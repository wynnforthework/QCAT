package scheduler

import (
	"context"
	"fmt"
	"log"
	"math"
	"sort"
	"sync"
	"time"

	"qcat/internal/config"
	"qcat/internal/database"
	"qcat/internal/exchange/account"
	"qcat/internal/hotlist"
	"qcat/internal/monitor"
)

// RiskScheduler é£é™©è°ƒåº¦å™¨
type RiskScheduler struct {
	config         *config.Config
	db             *database.DB
	accountManager *account.Manager
	isRunning      bool
	mu             sync.RWMutex
}

// NewRiskScheduler åˆ›å»ºé£é™©è°ƒåº¦å™¨
func NewRiskScheduler(cfg *config.Config, db *database.DB, accountManager *account.Manager) *RiskScheduler {
	return &RiskScheduler{
		config:         cfg,
		db:             db,
		accountManager: accountManager,
	}
}

func (rs *RiskScheduler) Start() error {
	rs.mu.Lock()
	defer rs.mu.Unlock()
	rs.isRunning = true
	log.Println("Risk scheduler started")
	return nil
}

func (rs *RiskScheduler) Stop() error {
	rs.mu.Lock()
	defer rs.mu.Unlock()
	rs.isRunning = false
	log.Println("Risk scheduler stopped")
	return nil
}

func (rs *RiskScheduler) HandleMonitoring(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing risk monitoring task: %s", task.Name)

	// TODO: å®ç°é£é™©ç›‘æ§é€»è¾‘
	// 1. æ£€æŸ¥ä¿è¯é‡‘æ¯”ç‡
	// 2. ç›‘æ§ä»“ä½é£é™©
	// 3. æ£€æµ‹å¼‚å¸¸è¡Œæƒ…
	// 4. è§¦å‘é£é™©æ§åˆ¶æªæ–½

	return nil
}

// HandleStopLossAdjustment å¤„ç†æ­¢ç›ˆæ­¢æŸçº¿è‡ªåŠ¨è°ƒæ•´ä»»åŠ¡
func (rs *RiskScheduler) HandleStopLossAdjustment(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing stop loss adjustment task: %s", task.Name)

	// å®ç°æ­¢ç›ˆæ­¢æŸçº¿è‡ªåŠ¨è°ƒæ•´é€»è¾‘
	// 1. åŸºäºATRè®¡ç®—åŠ¨æ€æ­¢æŸçº¿
	// 2. åŸºäºRVè®¡ç®—åŠ¨æ€æ­¢æŸçº¿
	// 3. æ ¹æ®å¸‚åœºçŠ¶æ€è°ƒæ•´å‚æ•°
	// 4. åº”ç”¨æ–°çš„æ­¢æŸè®¾ç½®

	// TODO: å®ç°åŸºäºATR/RVçš„åŠ¨æ€è°ƒæ•´ç®—æ³•
	log.Printf("Stop loss adjustment logic executed")
	return nil
}

// HandleFundDistribution å¤„ç†èµ„é‡‘åˆ†æ•£ä¸è½¬ç§»ä»»åŠ¡
func (rs *RiskScheduler) HandleFundDistribution(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing fund distribution task: %s", task.Name)

	// 1. æ£€æŸ¥èµ„é‡‘é›†ä¸­åº¦é£é™©
	riskAssessment, err := rs.assessFundConcentrationRisk(ctx)
	if err != nil {
		log.Printf("Failed to assess fund concentration risk: %v", err)
		return fmt.Errorf("failed to assess fund concentration risk: %w", err)
	}

	// 2. è®¡ç®—æœ€ä¼˜èµ„é‡‘åˆ†é…
	optimalDistribution, err := rs.calculateOptimalFundDistribution(ctx, riskAssessment)
	if err != nil {
		log.Printf("Failed to calculate optimal fund distribution: %v", err)
		return fmt.Errorf("failed to calculate optimal fund distribution: %w", err)
	}

	// 3. æ‰§è¡Œèµ„é‡‘è½¬ç§»æ“ä½œ
	transferResults, err := rs.executeFundTransfers(ctx, optimalDistribution)
	if err != nil {
		log.Printf("Failed to execute fund transfers: %v", err)
		return fmt.Errorf("failed to execute fund transfers: %w", err)
	}

	// 4. é›†æˆå†·é’±åŒ…åŠŸèƒ½
	err = rs.integrateColdWalletOperations(ctx, transferResults)
	if err != nil {
		log.Printf("Failed to integrate cold wallet operations: %v", err)
		// ä¸è¿”å›é”™è¯¯ï¼Œå› ä¸ºå†·é’±åŒ…æ“ä½œå¤±è´¥ä¸åº”è¯¥å½±å“ä¸»æµç¨‹
	}

	// 5. æ›´æ–°èµ„é‡‘ä¿æŠ¤åè®®
	err = rs.updateFundProtectionProtocol(ctx, optimalDistribution, transferResults)
	if err != nil {
		log.Printf("Failed to update fund protection protocol: %v", err)
		// ä¸è¿”å›é”™è¯¯ï¼Œå› ä¸ºåè®®æ›´æ–°å¤±è´¥ä¸åº”è¯¥å½±å“ä¸»æµç¨‹
	}

	log.Printf("Fund distribution completed successfully. Transferred %d operations", len(transferResults))
	return nil
}

// PositionScheduler ä»“ä½è°ƒåº¦å™¨
type PositionScheduler struct {
	config         *config.Config
	db             *database.DB
	accountManager *account.Manager
	isRunning      bool
	mu             sync.RWMutex
}

// NewPositionScheduler åˆ›å»ºä»“ä½è°ƒåº¦å™¨
func NewPositionScheduler(cfg *config.Config, db *database.DB, accountManager *account.Manager) *PositionScheduler {
	return &PositionScheduler{
		config:         cfg,
		db:             db,
		accountManager: accountManager,
	}
}

func (ps *PositionScheduler) Start() error {
	ps.mu.Lock()
	defer ps.mu.Unlock()
	ps.isRunning = true
	log.Println("Position scheduler started")
	return nil
}

func (ps *PositionScheduler) Stop() error {
	ps.mu.Lock()
	defer ps.mu.Unlock()
	ps.isRunning = false
	log.Println("Position scheduler stopped")
	return nil
}

func (ps *PositionScheduler) HandleOptimization(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing position optimization task: %s", task.Name)

	// TODO: å®ç°ä»“ä½ä¼˜åŒ–é€»è¾‘
	// 1. è·å–å½“å‰ä»“ä½
	// 2. è®¡ç®—æœ€ä¼˜ä»“ä½
	// 3. ç”Ÿæˆè°ƒä»“æŒ‡ä»¤
	// 4. æ‰§è¡Œä»“ä½è°ƒæ•´

	return nil
}

// HandleMultiStrategyHedging å¤„ç†è‡ªåŠ¨åŒ–å¤šç­–ç•¥å¯¹å†²ä»»åŠ¡
func (ps *PositionScheduler) HandleMultiStrategyHedging(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing multi-strategy hedging task: %s", task.Name)

	// å®ç°è‡ªåŠ¨åŒ–å¤šç­–ç•¥å¯¹å†²é€»è¾‘
	// 1. åˆ†æç­–ç•¥é—´ç›¸å…³æ€§
	// 2. è®¡ç®—åŠ¨æ€å¯¹å†²æ¯”ç‡
	// 3. æ‰§è¡Œè‡ªåŠ¨å¯¹å†²æ“ä½œ
	// 4. ç›‘æ§å¯¹å†²æ•ˆæœ

	// TODO: å®ç°è‡ªåŠ¨å¯¹å†²æ‰§è¡Œé€»è¾‘
	log.Printf("Multi-strategy hedging logic executed")
	return nil
}

// DataScheduler æ•°æ®è°ƒåº¦å™¨
type DataScheduler struct {
	config            *config.Config
	db                *database.DB
	isRunning         bool
	mu                sync.RWMutex
	integratedService *hotlist.IntegratedService
}

// NewDataScheduler åˆ›å»ºæ•°æ®è°ƒåº¦å™¨
func NewDataScheduler(cfg *config.Config, db *database.DB) *DataScheduler {
	// åˆ›å»ºé›†æˆæœåŠ¡
	integratedService := hotlist.NewIntegratedService(cfg, db)

	return &DataScheduler{
		config:            cfg,
		db:                db,
		integratedService: integratedService,
	}
}

func (ds *DataScheduler) Start() error {
	ds.mu.Lock()
	defer ds.mu.Unlock()
	ds.isRunning = true
	log.Println("Data scheduler started")
	return nil
}

func (ds *DataScheduler) Stop() error {
	ds.mu.Lock()
	defer ds.mu.Unlock()
	ds.isRunning = false
	log.Println("Data scheduler stopped")
	return nil
}

func (ds *DataScheduler) HandleCleaning(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing data cleaning task: %s", task.Name)

	// TODO: å®ç°æ•°æ®æ¸…æ´—é€»è¾‘
	// 1. æ£€æµ‹å¼‚å¸¸æ•°æ®
	// 2. æ¸…æ´—æ— æ•ˆæ•°æ®
	// 3. æ ¡æ­£æ•°æ®æ ¼å¼
	// 4. æ›´æ–°æ•°æ®è´¨é‡æŒ‡æ ‡

	return nil
}

// HandleHotCoinRecommendation å¤„ç†çƒ­é—¨å¸ç§æ¨èä»»åŠ¡
func (ds *DataScheduler) HandleHotCoinRecommendation(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing hot coin recommendation task: %s", task.Name)

	// å¯åŠ¨é›†æˆæœåŠ¡ï¼ˆå¦‚æœå°šæœªå¯åŠ¨ï¼‰
	if !ds.isServiceRunning() {
		err := ds.integratedService.Start(ctx)
		if err != nil {
			log.Printf("Failed to start integrated service: %v", err)
			return fmt.Errorf("failed to start integrated service: %w", err)
		}
	}

	// å¼ºåˆ¶æ›´æ–°æ¨è
	err := ds.integratedService.ForceUpdate(ctx)
	if err != nil {
		log.Printf("Failed to force update recommendations: %v", err)
		return fmt.Errorf("failed to force update recommendations: %w", err)
	}

	// è·å–æ¨èç»“æœ
	recommendations := ds.integratedService.GetRecommendations()

	// å‘é€æ¨èé€šçŸ¥
	err = ds.sendRecommendationNotifications(ctx, recommendations)
	if err != nil {
		log.Printf("Failed to send recommendation notifications: %v", err)
		// ä¸è¿”å›é”™è¯¯ï¼Œå› ä¸ºé€šçŸ¥å¤±è´¥ä¸åº”è¯¥å½±å“ä¸»æµç¨‹
	}

	log.Printf("Hot coin recommendation completed successfully. Generated %d recommendations", len(recommendations))
	return nil
}

// isServiceRunning æ£€æŸ¥é›†æˆæœåŠ¡æ˜¯å¦è¿è¡Œ
func (ds *DataScheduler) isServiceRunning() bool {
	status := ds.integratedService.GetStatus()
	if running, ok := status["is_running"].(bool); ok {
		return running
	}
	return false
}

// HandleFactorLibraryUpdate å¤„ç†å› å­åº“åŠ¨æ€æ›´æ–°ä»»åŠ¡
func (ds *DataScheduler) HandleFactorLibraryUpdate(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing factor library update task: %s", task.Name)

	// å®ç°å› å­åº“åŠ¨æ€æ›´æ–°é€»è¾‘
	// 1. æ‰«ææ–°çš„å¸‚åœºå› å­
	// 2. è¯„ä¼°å› å­æœ‰æ•ˆæ€§
	// 3. æ›´æ–°å› å­åº“
	// 4. æ¸…ç†è¿‡æœŸå› å­

	// TODO: å®ç°åŠ¨æ€å› å­å‘ç°å’Œè‡ªåŠ¨æ›´æ–°æœºåˆ¶
	log.Printf("Factor library update logic executed")
	return nil
}

// HandleMarketPatternRecognition å¤„ç†å¸‚åœºæ¨¡å¼è¯†åˆ«ä»»åŠ¡
func (ds *DataScheduler) HandleMarketPatternRecognition(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing market pattern recognition task: %s", task.Name)

	// å®ç°å¸‚åœºæ¨¡å¼è¯†åˆ«é€»è¾‘
	// 1. åˆ†æå½“å‰å¸‚åœºçŠ¶æ€
	// 2. è¯†åˆ«å¸‚åœºæ¨¡å¼å˜åŒ–
	// 3. è§¦å‘ç­–ç•¥åˆ‡æ¢
	// 4. æ›´æ–°æ¨¡å¼è¯†åˆ«æ¨¡å‹

	// TODO: å®ç°å®æ—¶æ¨¡å¼è¯†åˆ«ç®—æ³•
	log.Printf("Market pattern recognition logic executed")
	return nil
}

// SystemScheduler ç³»ç»Ÿè°ƒåº¦å™¨
type SystemScheduler struct {
	config    *config.Config
	db        *database.DB
	metrics   *monitor.MetricsCollector
	isRunning bool
	mu        sync.RWMutex
}

// NewSystemScheduler åˆ›å»ºç³»ç»Ÿè°ƒåº¦å™¨
func NewSystemScheduler(cfg *config.Config, db *database.DB, metrics *monitor.MetricsCollector) *SystemScheduler {
	return &SystemScheduler{
		config:  cfg,
		db:      db,
		metrics: metrics,
	}
}

func (ss *SystemScheduler) Start() error {
	ss.mu.Lock()
	defer ss.mu.Unlock()
	ss.isRunning = true
	log.Println("System scheduler started")
	return nil
}

func (ss *SystemScheduler) Stop() error {
	ss.mu.Lock()
	defer ss.mu.Unlock()
	ss.isRunning = false
	log.Println("System scheduler stopped")
	return nil
}

func (ss *SystemScheduler) HandleHealthCheck(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing system health check task: %s", task.Name)

	// TODO: å®ç°ç³»ç»Ÿå¥åº·æ£€æŸ¥é€»è¾‘
	// 1. æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨ç‡
	// 2. ç›‘æ§æœåŠ¡çŠ¶æ€
	// 3. æ£€æµ‹å¼‚å¸¸æƒ…å†µ
	// 4. è§¦å‘è‡ªæ„ˆæœºåˆ¶

	return nil
}

// LearningScheduler å­¦ä¹ è°ƒåº¦å™¨
type LearningScheduler struct {
	config    *config.Config
	db        *database.DB
	isRunning bool
	mu        sync.RWMutex
}

// NewLearningScheduler åˆ›å»ºå­¦ä¹ è°ƒåº¦å™¨
func NewLearningScheduler(cfg *config.Config, db *database.DB) *LearningScheduler {
	return &LearningScheduler{
		config: cfg,
		db:     db,
	}
}

func (ls *LearningScheduler) Start() error {
	ls.mu.Lock()
	defer ls.mu.Unlock()
	ls.isRunning = true
	log.Println("Learning scheduler started")
	return nil
}

func (ls *LearningScheduler) Stop() error {
	ls.mu.Lock()
	defer ls.mu.Unlock()
	ls.isRunning = false
	log.Println("Learning scheduler stopped")
	return nil
}

func (ls *LearningScheduler) HandleLearning(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing learning task: %s", task.Name)

	// TODO: å®ç°æœºå™¨å­¦ä¹ é€»è¾‘
	// 1. æ”¶é›†è®­ç»ƒæ•°æ®
	// 2. è®­ç»ƒæ¨¡å‹
	// 3. è¯„ä¼°æ¨¡å‹æ€§èƒ½
	// 4. æ›´æ–°ç­–ç•¥å‚æ•°

	return nil
}

// HandleAutoMLLearning å¤„ç†ç­–ç•¥è‡ªå­¦ä¹ AutoMLä»»åŠ¡
func (ls *LearningScheduler) HandleAutoMLLearning(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing AutoML learning task: %s", task.Name)

	// å®ç°AutoMLå­¦ä¹ é€»è¾‘
	// 1. è‡ªåŠ¨æ¨¡å‹é€‰æ‹©
	// 2. è¶…å‚æ•°ä¼˜åŒ–
	// 3. ç‰¹å¾å·¥ç¨‹
	// 4. æ¨¡å‹é›†æˆ

	// TODO: å®ç°è‡ªåŠ¨æ¨¡å‹é€‰æ‹©ç®—æ³•
	log.Printf("AutoML learning logic executed")
	return nil
}

// HandleGeneticEvolution å¤„ç†é—ä¼ æ·˜æ±°åˆ¶å‡çº§ä»»åŠ¡
func (ls *LearningScheduler) HandleGeneticEvolution(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing genetic evolution task: %s", task.Name)

	// å®ç°é—ä¼ æ·˜æ±°åˆ¶å‡çº§é€»è¾‘
	// 1. ç­–ç•¥åŸºå› ç¼–ç 
	// 2. æ‰§è¡Œå˜å¼‚æ“ä½œ
	// 3. é€‚åº”åº¦è¯„ä¼°
	// 4. é€‰æ‹©å’Œç¹æ®–

	// TODO: å®ç°è‡ªåŠ¨å˜å¼‚æœºåˆ¶
	log.Printf("Genetic evolution logic executed")
	return nil
}

// çƒ­é—¨å¸ç§æ¨èç›¸å…³æ•°æ®ç»“æ„

// MarketData å¸‚åœºæ•°æ®
type MarketData struct {
	Symbol          string
	Price           float64
	Volume24h       float64
	VolumeChange24h float64
	PriceChange24h  float64
	Volatility      float64
	FundingRate     float64
	OpenInterest    float64
	OIChange24h     float64
	Timestamp       time.Time
}

// HotScore çƒ­åº¦è¯„åˆ†
type HotScore struct {
	Symbol       string
	TotalScore   float64
	VolumeScore  float64
	PriceScore   float64
	FundingScore float64
	OIScore      float64
	TrendScore   float64
	RiskLevel    string
	Timestamp    time.Time
}

// Recommendation æ¨èç»“æœ
type Recommendation struct {
	Symbol          string
	Score           float64
	RiskLevel       string
	PriceRange      [2]float64 // [min, max]
	SafeLeverage    float64
	MarketSentiment string
	Reason          string
	Timestamp       time.Time
}

// çƒ­é—¨å¸ç§æ¨èç›¸å…³æ–¹æ³•

// getAvailableSymbols è·å–æ‰€æœ‰å¯ç”¨çš„äº¤æ˜“å¯¹
func (ds *DataScheduler) getAvailableSymbols(ctx context.Context) ([]string, error) {
	// ä»æ•°æ®åº“è·å–æ´»è·ƒçš„äº¤æ˜“å¯¹
	query := `
		SELECT DISTINCT symbol
		FROM market_data
		WHERE updated_at > NOW() - INTERVAL '1 hour'
		AND volume_24h > 1000000  -- æœ€å°äº¤æ˜“é‡è¿‡æ»¤
		ORDER BY symbol
	`

	rows, err := ds.db.QueryContext(ctx, query)
	if err != nil {
		return nil, fmt.Errorf("failed to query symbols: %w", err)
	}
	defer rows.Close()

	var symbols []string
	for rows.Next() {
		var symbol string
		if err := rows.Scan(&symbol); err != nil {
			return nil, fmt.Errorf("failed to scan symbol: %w", err)
		}
		symbols = append(symbols, symbol)
	}

	// å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤çš„çƒ­é—¨å¸ç§åˆ—è¡¨
	if len(symbols) == 0 {
		symbols = []string{
			"BTCUSDT", "ETHUSDT", "BNBUSDT", "ADAUSDT", "SOLUSDT",
			"XRPUSDT", "DOTUSDT", "DOGEUSDT", "AVAXUSDT", "MATICUSDT",
			"LINKUSDT", "LTCUSDT", "UNIUSDT", "ATOMUSDT", "FILUSDT",
		}
	}

	return symbols, nil
}

// collectMarketData æ”¶é›†å¸‚åœºæ•°æ®
func (ds *DataScheduler) collectMarketData(ctx context.Context, symbols []string) ([]*MarketData, error) {
	var marketData []*MarketData

	for _, symbol := range symbols {
		// ä»æ•°æ®åº“è·å–æœ€æ–°çš„å¸‚åœºæ•°æ®
		query := `
			SELECT
				symbol,
				price,
				volume_24h,
				volume_change_24h,
				price_change_24h,
				volatility,
				funding_rate,
				open_interest,
				oi_change_24h,
				updated_at
			FROM market_data
			WHERE symbol = $1
			ORDER BY updated_at DESC
			LIMIT 1
		`

		var data MarketData
		err := ds.db.QueryRowContext(ctx, query, symbol).Scan(
			&data.Symbol,
			&data.Price,
			&data.Volume24h,
			&data.VolumeChange24h,
			&data.PriceChange24h,
			&data.Volatility,
			&data.FundingRate,
			&data.OpenInterest,
			&data.OIChange24h,
			&data.Timestamp,
		)

		if err != nil {
			// å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ç”¨äºæµ‹è¯•
			log.Printf("No market data found for %s, using mock data: %v", symbol, err)
			data = MarketData{
				Symbol:          symbol,
				Price:           50000.0 + float64(len(symbol)*1000), // æ¨¡æ‹Ÿä»·æ ¼
				Volume24h:       1000000.0 + float64(len(symbol)*100000),
				VolumeChange24h: -10.0 + float64(len(symbol)%20),
				PriceChange24h:  -5.0 + float64(len(symbol)%10),
				Volatility:      0.02 + float64(len(symbol)%5)*0.01,
				FundingRate:     0.0001 + float64(len(symbol)%3)*0.0001,
				OpenInterest:    500000.0 + float64(len(symbol)*50000),
				OIChange24h:     -5.0 + float64(len(symbol)%10),
				Timestamp:       time.Now(),
			}
		}

		marketData = append(marketData, &data)
	}

	return marketData, nil
}

// analyzeHotness åˆ†æçƒ­åº¦æŒ‡æ ‡
func (ds *DataScheduler) analyzeHotness(ctx context.Context, marketData []*MarketData) ([]*HotScore, error) {
	var hotScores []*HotScore

	for _, data := range marketData {
		score := &HotScore{
			Symbol:    data.Symbol,
			Timestamp: time.Now(),
		}

		// 1. äº¤æ˜“é‡è¯„åˆ† (0-30åˆ†)
		volumeScore := ds.calculateVolumeScore(data)
		score.VolumeScore = volumeScore

		// 2. ä»·æ ¼å˜åŠ¨è¯„åˆ† (0-25åˆ†)
		priceScore := ds.calculatePriceScore(data)
		score.PriceScore = priceScore

		// 3. èµ„é‡‘è´¹ç‡è¯„åˆ† (0-20åˆ†)
		fundingScore := ds.calculateFundingScore(data)
		score.FundingScore = fundingScore

		// 4. æŒä»“é‡è¯„åˆ† (0-15åˆ†)
		oiScore := ds.calculateOIScore(data)
		score.OIScore = oiScore

		// 5. è¶‹åŠ¿è¯„åˆ† (0-10åˆ†)
		trendScore := ds.calculateTrendScore(data)
		score.TrendScore = trendScore

		// è®¡ç®—æ€»åˆ†
		score.TotalScore = volumeScore + priceScore + fundingScore + oiScore + trendScore

		// ç¡®å®šé£é™©ç­‰çº§
		score.RiskLevel = ds.determineRiskLevel(score.TotalScore, data)

		hotScores = append(hotScores, score)
	}

	// æŒ‰æ€»åˆ†æ’åº
	sort.Slice(hotScores, func(i, j int) bool {
		return hotScores[i].TotalScore > hotScores[j].TotalScore
	})

	return hotScores, nil
}

// calculateVolumeScore è®¡ç®—äº¤æ˜“é‡è¯„åˆ†
func (ds *DataScheduler) calculateVolumeScore(data *MarketData) float64 {
	// åŸºç¡€äº¤æ˜“é‡è¯„åˆ† (0-15åˆ†)
	baseScore := math.Min(15, math.Log10(data.Volume24h/1000000)*5)
	if baseScore < 0 {
		baseScore = 0
	}

	// äº¤æ˜“é‡å˜åŒ–è¯„åˆ† (0-15åˆ†)
	changeScore := math.Min(15, math.Max(0, data.VolumeChange24h/10))

	return baseScore + changeScore
}

// calculatePriceScore è®¡ç®—ä»·æ ¼å˜åŠ¨è¯„åˆ†
func (ds *DataScheduler) calculatePriceScore(data *MarketData) float64 {
	// ä»·æ ¼å˜åŒ–å¹…åº¦è¯„åˆ† (0-15åˆ†)
	changeScore := math.Min(15, math.Abs(data.PriceChange24h)/2)

	// æ³¢åŠ¨ç‡è¯„åˆ† (0-10åˆ†)
	volatilityScore := math.Min(10, data.Volatility*200)

	return changeScore + volatilityScore
}

// calculateFundingScore è®¡ç®—èµ„é‡‘è´¹ç‡è¯„åˆ†
func (ds *DataScheduler) calculateFundingScore(data *MarketData) float64 {
	// èµ„é‡‘è´¹ç‡å¼‚å¸¸ç¨‹åº¦è¯„åˆ†
	absRate := math.Abs(data.FundingRate)

	// æ­£å¸¸èµ„é‡‘è´¹ç‡èŒƒå›´æ˜¯ -0.01% åˆ° 0.01%
	if absRate > 0.001 {
		return math.Min(20, absRate*10000) // è¶…å‡ºæ­£å¸¸èŒƒå›´ç»™é«˜åˆ†
	}

	return absRate * 5000 // æ­£å¸¸èŒƒå›´å†…ç»™è¾ƒä½åˆ†
}

// calculateOIScore è®¡ç®—æŒä»“é‡è¯„åˆ†
func (ds *DataScheduler) calculateOIScore(data *MarketData) float64 {
	// æŒä»“é‡å˜åŒ–è¯„åˆ†
	changeScore := math.Min(15, math.Max(0, math.Abs(data.OIChange24h)/5))

	return changeScore
}

// calculateTrendScore è®¡ç®—è¶‹åŠ¿è¯„åˆ†
func (ds *DataScheduler) calculateTrendScore(data *MarketData) float64 {
	// åŸºäºä»·æ ¼å˜åŒ–å’Œäº¤æ˜“é‡å˜åŒ–çš„è¶‹åŠ¿å¼ºåº¦
	priceWeight := math.Abs(data.PriceChange24h) / 10
	volumeWeight := data.VolumeChange24h / 20

	trendStrength := (priceWeight + volumeWeight) / 2
	return math.Min(10, math.Max(0, trendStrength))
}

// determineRiskLevel ç¡®å®šé£é™©ç­‰çº§
func (ds *DataScheduler) determineRiskLevel(totalScore float64, data *MarketData) string {
	// åŸºäºæ€»åˆ†å’Œæ³¢åŠ¨ç‡ç¡®å®šé£é™©ç­‰çº§
	if totalScore >= 80 || data.Volatility > 0.1 {
		return "HIGH"
	} else if totalScore >= 60 || data.Volatility > 0.05 {
		return "MEDIUM"
	} else {
		return "LOW"
	}
}

// generateRecommendations ç”Ÿæˆæ¨èåˆ—è¡¨
func (ds *DataScheduler) generateRecommendations(ctx context.Context, hotScores []*HotScore) ([]*Recommendation, error) {
	// è½¬æ¢ä¸ºç¬¦å·åˆ—è¡¨
	symbols := make([]string, len(hotScores))
	for i, score := range hotScores {
		symbols[i] = score.Symbol
	}

	// ä½¿ç”¨é›†æˆæœåŠ¡ç”Ÿæˆæ¨è
	enhancedRecs := ds.integratedService.GetRecommendations()
	if len(enhancedRecs) == 0 {
		// å¦‚æœæ²¡æœ‰ç¼“å­˜çš„æ¨èï¼Œå¼ºåˆ¶æ›´æ–°
		err := ds.integratedService.ForceUpdate(ctx)
		if err != nil {
			return nil, fmt.Errorf("failed to force update recommendations: %w", err)
		}
		enhancedRecs = ds.integratedService.GetRecommendations()
	}

	// è½¬æ¢ä¸ºæ—§æ ¼å¼ä»¥ä¿æŒå…¼å®¹æ€§
	var recommendations []*Recommendation
	for _, enhancedRec := range enhancedRecs {
		recommendation := &Recommendation{
			Symbol:          enhancedRec.Symbol,
			Score:           enhancedRec.Score,
			RiskLevel:       enhancedRec.RiskLevel,
			PriceRange:      enhancedRec.PriceRange,
			SafeLeverage:    enhancedRec.SafeLeverage,
			MarketSentiment: enhancedRec.MarketSentiment,
			Reason:          enhancedRec.Reason,
			Timestamp:       enhancedRec.Timestamp,
		}
		recommendations = append(recommendations, recommendation)
	}

	return recommendations, nil
}

// calculateSafeLeverage è®¡ç®—å®‰å…¨æ æ†å€æ•°
func (ds *DataScheduler) calculateSafeLeverage(riskLevel string) float64 {
	switch riskLevel {
	case "HIGH":
		return 2.0 // é«˜é£é™©å¸ç§å»ºè®®ä½æ æ†
	case "MEDIUM":
		return 5.0 // ä¸­é£é™©å¸ç§å»ºè®®ä¸­ç­‰æ æ†
	case "LOW":
		return 10.0 // ä½é£é™©å¸ç§å¯ä»¥ä½¿ç”¨è¾ƒé«˜æ æ†
	default:
		return 1.0 // é»˜è®¤æ— æ æ†
	}
}

// determineMarketSentiment ç¡®å®šå¸‚åœºæƒ…ç»ª
func (ds *DataScheduler) determineMarketSentiment(score *HotScore) string {
	if score.TotalScore >= 80 {
		return "EXTREMELY_BULLISH"
	} else if score.TotalScore >= 70 {
		return "BULLISH"
	} else if score.TotalScore >= 60 {
		return "NEUTRAL_BULLISH"
	} else if score.TotalScore >= 50 {
		return "NEUTRAL"
	} else {
		return "BEARISH"
	}
}

// generateRecommendationReason ç”Ÿæˆæ¨èç†ç”±
func (ds *DataScheduler) generateRecommendationReason(score *HotScore) string {
	reasons := []string{}

	if score.VolumeScore > 20 {
		reasons = append(reasons, "äº¤æ˜“é‡å¼‚å¸¸æ´»è·ƒ")
	}
	if score.PriceScore > 15 {
		reasons = append(reasons, "ä»·æ ¼æ³¢åŠ¨æ˜¾è‘—")
	}
	if score.FundingScore > 10 {
		reasons = append(reasons, "èµ„é‡‘è´¹ç‡å¼‚å¸¸")
	}
	if score.OIScore > 8 {
		reasons = append(reasons, "æŒä»“é‡å˜åŒ–æ˜æ˜¾")
	}
	if score.TrendScore > 6 {
		reasons = append(reasons, "è¶‹åŠ¿å¼ºåŠ²")
	}

	if len(reasons) == 0 {
		return "ç»¼åˆæŒ‡æ ‡è¡¨ç°è‰¯å¥½"
	}

	result := "æ¨èç†ç”±: "
	for i, reason := range reasons {
		if i > 0 {
			result += ", "
		}
		result += reason
	}

	return result
}

// updateHotlistDatabase æ›´æ–°çƒ­é—¨å¸ç§æ•°æ®åº“
func (ds *DataScheduler) updateHotlistDatabase(ctx context.Context, recommendations []*Recommendation) error {
	// æ¸…ç†æ—§çš„æ¨èæ•°æ® (ä¿ç•™æœ€è¿‘24å°æ—¶çš„æ•°æ®)
	cleanupQuery := `
		DELETE FROM hotlist_recommendations
		WHERE created_at < NOW() - INTERVAL '24 hours'
	`

	_, err := ds.db.ExecContext(ctx, cleanupQuery)
	if err != nil {
		log.Printf("Failed to cleanup old recommendations: %v", err)
		// ä¸è¿”å›é”™è¯¯ï¼Œç»§ç»­æ‰§è¡Œ
	}

	// æ’å…¥æ–°çš„æ¨èæ•°æ®
	insertQuery := `
		INSERT INTO hotlist_recommendations (
			symbol, score, risk_level, price_min, price_max,
			safe_leverage, market_sentiment, reason, created_at
		) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
		ON CONFLICT (symbol) DO UPDATE SET
			score = EXCLUDED.score,
			risk_level = EXCLUDED.risk_level,
			price_min = EXCLUDED.price_min,
			price_max = EXCLUDED.price_max,
			safe_leverage = EXCLUDED.safe_leverage,
			market_sentiment = EXCLUDED.market_sentiment,
			reason = EXCLUDED.reason,
			updated_at = NOW()
	`

	for _, rec := range recommendations {
		_, err := ds.db.ExecContext(ctx, insertQuery,
			rec.Symbol,
			rec.Score,
			rec.RiskLevel,
			rec.PriceRange[0],
			rec.PriceRange[1],
			rec.SafeLeverage,
			rec.MarketSentiment,
			rec.Reason,
			rec.Timestamp,
		)

		if err != nil {
			log.Printf("Failed to insert recommendation for %s: %v", rec.Symbol, err)
			// ç»§ç»­å¤„ç†å…¶ä»–æ¨èï¼Œä¸è¿”å›é”™è¯¯
		}
	}

	log.Printf("Successfully updated %d recommendations in database", len(recommendations))
	return nil
}

// sendRecommendationNotifications å‘é€æ¨èé€šçŸ¥ (æ”¯æŒå¢å¼ºæ¨è)
func (ds *DataScheduler) sendRecommendationNotifications(ctx context.Context, recommendations []*hotlist.EnhancedRecommendation) error {
	// åªé€šçŸ¥é«˜åˆ†æ¨è (åˆ†æ•° >= 75)
	highScoreRecs := []*hotlist.EnhancedRecommendation{}
	for _, rec := range recommendations {
		if rec.Score >= 75 {
			highScoreRecs = append(highScoreRecs, rec)
		}
	}

	if len(highScoreRecs) == 0 {
		log.Printf("No high-score recommendations to notify")
		return nil
	}

	// æ„å»ºé€šçŸ¥æ¶ˆæ¯
	message := fmt.Sprintf("ğŸ”¥ å‘ç° %d ä¸ªçƒ­é—¨å¸ç§æ¨è:\n", len(highScoreRecs))
	for i, rec := range highScoreRecs {
		if i >= 5 { // æœ€å¤šæ˜¾ç¤º5ä¸ª
			break
		}
		message += fmt.Sprintf("â€¢ %s (è¯„åˆ†: %.1f, é£é™©: %s, ç½®ä¿¡åº¦: %.1f%%)\n",
			rec.Symbol, rec.Score, rec.RiskLevel, rec.Confidence*100)
	}

	// è¿™é‡Œå¯ä»¥é›†æˆå®é™…çš„é€šçŸ¥ç³»ç»Ÿ (å¦‚Webhookã€é‚®ä»¶ã€Slackç­‰)
	// ç›®å‰åªè®°å½•æ—¥å¿—
	log.Printf("Notification: %s", message)

	// TODO: å®ç°å®é™…çš„é€šçŸ¥å‘é€é€»è¾‘
	// ä¾‹å¦‚: å‘é€åˆ°Webhookã€é‚®ä»¶ã€Slackç­‰

	return nil
}

// èµ„é‡‘åˆ†æ•£ä¸è½¬ç§»ç›¸å…³æ•°æ®ç»“æ„

// FundConcentrationRisk èµ„é‡‘é›†ä¸­åº¦é£é™©è¯„ä¼°
type FundConcentrationRisk struct {
	TotalFunds           float64            `json:"total_funds"`
	ExchangeDistribution map[string]float64 `json:"exchange_distribution"`
	WalletDistribution   map[string]float64 `json:"wallet_distribution"`
	RiskLevel            string             `json:"risk_level"`
	ConcentrationRatio   float64            `json:"concentration_ratio"`
	RiskFactors          map[string]float64 `json:"risk_factors"`
	Recommendations      []string           `json:"recommendations"`
	Timestamp            time.Time          `json:"timestamp"`
}

// OptimalFundDistribution æœ€ä¼˜èµ„é‡‘åˆ†é…
type OptimalFundDistribution struct {
	TargetDistribution    map[string]float64 `json:"target_distribution"`
	CurrentDistribution   map[string]float64 `json:"current_distribution"`
	RequiredTransfers     []*FundTransfer    `json:"required_transfers"`
	ExpectedRiskReduction float64            `json:"expected_risk_reduction"`
	EstimatedCost         float64            `json:"estimated_cost"`
	Priority              int                `json:"priority"`
	Timestamp             time.Time          `json:"timestamp"`
}

// FundTransfer èµ„é‡‘è½¬ç§»æ“ä½œ
type FundTransfer struct {
	ID               string                 `json:"id"`
	Type             string                 `json:"type"` // HOT_TO_COLD, COLD_TO_HOT, EXCHANGE_REBALANCE
	FromAddress      string                 `json:"from_address"`
	ToAddress        string                 `json:"to_address"`
	Amount           float64                `json:"amount"`
	Currency         string                 `json:"currency"`
	Status           string                 `json:"status"`
	Priority         int                    `json:"priority"`
	EstimatedFee     float64                `json:"estimated_fee"`
	ActualFee        float64                `json:"actual_fee"`
	TransactionHash  string                 `json:"transaction_hash"`
	Confirmations    int                    `json:"confirmations"`
	RequiredConfirms int                    `json:"required_confirms"`
	CreatedAt        time.Time              `json:"created_at"`
	ExecutedAt       *time.Time             `json:"executed_at"`
	CompletedAt      *time.Time             `json:"completed_at"`
	Metadata         map[string]interface{} `json:"metadata"`
}

// TransferResult è½¬ç§»ç»“æœ
type TransferResult struct {
	Transfer      *FundTransfer          `json:"transfer"`
	Success       bool                   `json:"success"`
	Error         string                 `json:"error,omitempty"`
	ActualAmount  float64                `json:"actual_amount"`
	ExecutionTime time.Duration          `json:"execution_time"`
	Metadata      map[string]interface{} `json:"metadata"`
}

// ColdWalletOperation å†·é’±åŒ…æ“ä½œ
type ColdWalletOperation struct {
	ID            string                 `json:"id"`
	Type          string                 `json:"type"` // DEPOSIT, WITHDRAW, BALANCE_CHECK
	WalletAddress string                 `json:"wallet_address"`
	Amount        float64                `json:"amount"`
	Currency      string                 `json:"currency"`
	Status        string                 `json:"status"`
	SecurityLevel string                 `json:"security_level"`
	RequiredSigs  int                    `json:"required_sigs"`
	ProvidedSigs  int                    `json:"provided_sigs"`
	CreatedAt     time.Time              `json:"created_at"`
	ExecutedAt    *time.Time             `json:"executed_at"`
	Metadata      map[string]interface{} `json:"metadata"`
}

// assessFundConcentrationRisk è¯„ä¼°èµ„é‡‘é›†ä¸­åº¦é£é™©
func (rs *RiskScheduler) assessFundConcentrationRisk(ctx context.Context) (*FundConcentrationRisk, error) {
	// 1. è·å–å½“å‰èµ„é‡‘åˆ†å¸ƒ
	exchangeDistribution, err := rs.getExchangeFundDistribution(ctx)
	if err != nil {
		return nil, fmt.Errorf("failed to get exchange fund distribution: %w", err)
	}

	walletDistribution, err := rs.getWalletFundDistribution(ctx)
	if err != nil {
		return nil, fmt.Errorf("failed to get wallet fund distribution: %w", err)
	}

	// 2. è®¡ç®—æ€»èµ„é‡‘
	totalFunds := 0.0
	for _, amount := range exchangeDistribution {
		totalFunds += amount
	}
	for _, amount := range walletDistribution {
		totalFunds += amount
	}

	// 3. è®¡ç®—é›†ä¸­åº¦æ¯”ç‡
	concentrationRatio := rs.calculateConcentrationRatio(exchangeDistribution, walletDistribution)

	// 4. è¯„ä¼°é£é™©å› å­
	riskFactors := rs.calculateRiskFactors(exchangeDistribution, walletDistribution, totalFunds)

	// 5. ç¡®å®šé£é™©ç­‰çº§
	riskLevel := rs.determineRiskLevel(concentrationRatio, riskFactors)

	// 6. ç”Ÿæˆå»ºè®®
	recommendations := rs.generateRiskRecommendations(riskLevel, concentrationRatio, riskFactors)

	assessment := &FundConcentrationRisk{
		TotalFunds:           totalFunds,
		ExchangeDistribution: exchangeDistribution,
		WalletDistribution:   walletDistribution,
		RiskLevel:            riskLevel,
		ConcentrationRatio:   concentrationRatio,
		RiskFactors:          riskFactors,
		Recommendations:      recommendations,
		Timestamp:            time.Now(),
	}

	log.Printf("Fund concentration risk assessment: Level=%s, Ratio=%.4f, Total=%.2f",
		riskLevel, concentrationRatio, totalFunds)

	return assessment, nil
}

// getExchangeFundDistribution è·å–äº¤æ˜“æ‰€èµ„é‡‘åˆ†å¸ƒ
func (rs *RiskScheduler) getExchangeFundDistribution(ctx context.Context) (map[string]float64, error) {
	query := `
		SELECT exchange_name, SUM(balance) as total_balance
		FROM exchange_balances
		WHERE updated_at > NOW() - INTERVAL '1 hour'
		GROUP BY exchange_name
	`

	rows, err := rs.db.QueryContext(ctx, query)
	if err != nil {
		return nil, fmt.Errorf("failed to query exchange balances: %w", err)
	}
	defer rows.Close()

	distribution := make(map[string]float64)
	for rows.Next() {
		var exchangeName string
		var balance float64
		if err := rows.Scan(&exchangeName, &balance); err != nil {
			return nil, fmt.Errorf("failed to scan exchange balance: %w", err)
		}
		distribution[exchangeName] = balance
	}

	// å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
	if len(distribution) == 0 {
		distribution = map[string]float64{
			"binance": 50000.0,
			"okx":     30000.0,
			"bybit":   20000.0,
		}
	}

	return distribution, nil
}

// getWalletFundDistribution è·å–é’±åŒ…èµ„é‡‘åˆ†å¸ƒ
func (rs *RiskScheduler) getWalletFundDistribution(ctx context.Context) (map[string]float64, error) {
	query := `
		SELECT wallet_type, SUM(balance) as total_balance
		FROM wallet_balances
		WHERE updated_at > NOW() - INTERVAL '1 hour'
		GROUP BY wallet_type
	`

	rows, err := rs.db.QueryContext(ctx, query)
	if err != nil {
		return nil, fmt.Errorf("failed to query wallet balances: %w", err)
	}
	defer rows.Close()

	distribution := make(map[string]float64)
	for rows.Next() {
		var walletType string
		var balance float64
		if err := rows.Scan(&walletType, &balance); err != nil {
			return nil, fmt.Errorf("failed to scan wallet balance: %w", err)
		}
		distribution[walletType] = balance
	}

	// å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
	if len(distribution) == 0 {
		distribution = map[string]float64{
			"hot_wallet":  15000.0,
			"cold_wallet": 35000.0,
		}
	}

	return distribution, nil
}

// calculateConcentrationRatio è®¡ç®—é›†ä¸­åº¦æ¯”ç‡
func (rs *RiskScheduler) calculateConcentrationRatio(exchangeDist, walletDist map[string]float64) float64 {
	// è®¡ç®—æœ€å¤§å•ä¸€é›†ä¸­åº¦
	maxConcentration := 0.0
	totalFunds := 0.0

	// è®¡ç®—æ€»èµ„é‡‘
	for _, amount := range exchangeDist {
		totalFunds += amount
	}
	for _, amount := range walletDist {
		totalFunds += amount
	}

	// æ‰¾å‡ºæœ€å¤§å•ä¸€é›†ä¸­åº¦
	for _, amount := range exchangeDist {
		ratio := amount / totalFunds
		if ratio > maxConcentration {
			maxConcentration = ratio
		}
	}
	for _, amount := range walletDist {
		ratio := amount / totalFunds
		if ratio > maxConcentration {
			maxConcentration = ratio
		}
	}

	return maxConcentration
}

// calculateRiskFactors è®¡ç®—é£é™©å› å­
func (rs *RiskScheduler) calculateRiskFactors(exchangeDist, walletDist map[string]float64, totalFunds float64) map[string]float64 {
	riskFactors := make(map[string]float64)

	// 1. äº¤æ˜“æ‰€é›†ä¸­åº¦é£é™©
	exchangeRisk := 0.0
	for _, amount := range exchangeDist {
		ratio := amount / totalFunds
		if ratio > 0.5 { // å•ä¸€äº¤æ˜“æ‰€è¶…è¿‡50%
			exchangeRisk += (ratio - 0.5) * 2.0 // è¶…å‡ºéƒ¨åˆ†åŠ å€è®¡ç®—é£é™©
		}
	}
	riskFactors["exchange_concentration"] = math.Min(1.0, exchangeRisk)

	// 2. çƒ­é’±åŒ…é£é™©
	hotWalletRisk := 0.0
	if hotAmount, exists := walletDist["hot_wallet"]; exists {
		hotRatio := hotAmount / totalFunds
		if hotRatio > 0.2 { // çƒ­é’±åŒ…è¶…è¿‡20%
			hotWalletRisk = (hotRatio - 0.2) * 2.5
		}
	}
	riskFactors["hot_wallet_risk"] = math.Min(1.0, hotWalletRisk)

	// 3. åœ°ç†åˆ†å¸ƒé£é™© (ç®€åŒ–å¤„ç†)
	geoRisk := 0.3 // å‡è®¾ä¸­ç­‰åœ°ç†é£é™©
	riskFactors["geographic_risk"] = geoRisk

	// 4. æµåŠ¨æ€§é£é™©
	liquidityRisk := 0.0
	exchangeCount := len(exchangeDist)
	if exchangeCount < 2 {
		liquidityRisk = 0.8 // åªæœ‰ä¸€ä¸ªäº¤æ˜“æ‰€ï¼ŒæµåŠ¨æ€§é£é™©å¾ˆé«˜
	} else if exchangeCount < 3 {
		liquidityRisk = 0.4 // ä¸¤ä¸ªäº¤æ˜“æ‰€ï¼Œä¸­ç­‰é£é™©
	} else {
		liquidityRisk = 0.1 // ä¸‰ä¸ªä»¥ä¸Šäº¤æ˜“æ‰€ï¼Œä½é£é™©
	}
	riskFactors["liquidity_risk"] = liquidityRisk

	// 5. æŠ€æœ¯é£é™©
	techRisk := 0.2 // å‡è®¾åŸºç¡€æŠ€æœ¯é£é™©
	riskFactors["technical_risk"] = techRisk

	return riskFactors
}

// determineRiskLevel ç¡®å®šé£é™©ç­‰çº§
func (rs *RiskScheduler) determineRiskLevel(concentrationRatio float64, riskFactors map[string]float64) string {
	// è®¡ç®—ç»¼åˆé£é™©åˆ†æ•°
	totalRisk := concentrationRatio * 0.4 // é›†ä¸­åº¦æƒé‡40%

	for factor, value := range riskFactors {
		switch factor {
		case "exchange_concentration":
			totalRisk += value * 0.25 // äº¤æ˜“æ‰€é›†ä¸­åº¦æƒé‡25%
		case "hot_wallet_risk":
			totalRisk += value * 0.15 // çƒ­é’±åŒ…é£é™©æƒé‡15%
		case "geographic_risk":
			totalRisk += value * 0.1 // åœ°ç†é£é™©æƒé‡10%
		case "liquidity_risk":
			totalRisk += value * 0.05 // æµåŠ¨æ€§é£é™©æƒé‡5%
		case "technical_risk":
			totalRisk += value * 0.05 // æŠ€æœ¯é£é™©æƒé‡5%
		}
	}

	// æ ¹æ®æ€»é£é™©åˆ†æ•°ç¡®å®šç­‰çº§
	if totalRisk >= 0.8 {
		return "CRITICAL"
	} else if totalRisk >= 0.6 {
		return "HIGH"
	} else if totalRisk >= 0.4 {
		return "MEDIUM"
	} else if totalRisk >= 0.2 {
		return "LOW"
	} else {
		return "MINIMAL"
	}
}

// generateRiskRecommendations ç”Ÿæˆé£é™©å»ºè®®
func (rs *RiskScheduler) generateRiskRecommendations(riskLevel string, concentrationRatio float64, riskFactors map[string]float64) []string {
	var recommendations []string

	// åŸºäºé£é™©ç­‰çº§çš„é€šç”¨å»ºè®®
	switch riskLevel {
	case "CRITICAL":
		recommendations = append(recommendations, "ç«‹å³æ‰§è¡Œç´§æ€¥èµ„é‡‘åˆ†æ•£æ“ä½œ")
		recommendations = append(recommendations, "æš‚åœå¤§é¢äº¤æ˜“ç›´åˆ°é£é™©é™ä½")
	case "HIGH":
		recommendations = append(recommendations, "åœ¨24å°æ—¶å†…æ‰§è¡Œèµ„é‡‘é‡æ–°åˆ†é…")
		recommendations = append(recommendations, "å¢åŠ å†·é’±åŒ…å­˜å‚¨æ¯”ä¾‹")
	case "MEDIUM":
		recommendations = append(recommendations, "è€ƒè™‘åœ¨ä¸€å‘¨å†…ä¼˜åŒ–èµ„é‡‘åˆ†å¸ƒ")
		recommendations = append(recommendations, "ç›‘æ§äº¤æ˜“æ‰€é£é™©çŠ¶å†µ")
	case "LOW":
		recommendations = append(recommendations, "ä¿æŒå½“å‰åˆ†æ•£ç­–ç•¥")
		recommendations = append(recommendations, "å®šæœŸè¯„ä¼°èµ„é‡‘åˆ†å¸ƒ")
	}

	// åŸºäºå…·ä½“é£é™©å› å­çš„å»ºè®®
	if riskFactors["exchange_concentration"] > 0.6 {
		recommendations = append(recommendations, "å‡å°‘å•ä¸€äº¤æ˜“æ‰€èµ„é‡‘é›†ä¸­åº¦")
		recommendations = append(recommendations, "è€ƒè™‘å¢åŠ æ–°çš„äº¤æ˜“æ‰€")
	}

	if riskFactors["hot_wallet_risk"] > 0.5 {
		recommendations = append(recommendations, "å°†éƒ¨åˆ†çƒ­é’±åŒ…èµ„é‡‘è½¬ç§»åˆ°å†·é’±åŒ…")
		recommendations = append(recommendations, "åŠ å¼ºçƒ­é’±åŒ…å®‰å…¨ç›‘æ§")
	}

	if riskFactors["liquidity_risk"] > 0.6 {
		recommendations = append(recommendations, "å¢åŠ äº¤æ˜“æ‰€æ•°é‡ä»¥æé«˜æµåŠ¨æ€§")
		recommendations = append(recommendations, "å»ºç«‹åº”æ€¥æµåŠ¨æ€§å‚¨å¤‡")
	}

	if concentrationRatio > 0.7 {
		recommendations = append(recommendations, "ç´§æ€¥åˆ†æ•£èµ„é‡‘ï¼Œé™ä½å•ç‚¹é£é™©")
	}

	return recommendations
}

// calculateOptimalFundDistribution è®¡ç®—æœ€ä¼˜èµ„é‡‘åˆ†é…
func (rs *RiskScheduler) calculateOptimalFundDistribution(ctx context.Context, riskAssessment *FundConcentrationRisk) (*OptimalFundDistribution, error) {
	// 1. å®šä¹‰ç›®æ ‡åˆ†é…æ¯”ä¾‹
	targetDistribution := rs.calculateTargetDistribution(riskAssessment)

	// 2. è·å–å½“å‰åˆ†é…
	currentDistribution := make(map[string]float64)
	for k, v := range riskAssessment.ExchangeDistribution {
		currentDistribution[k] = v / riskAssessment.TotalFunds
	}
	for k, v := range riskAssessment.WalletDistribution {
		currentDistribution[k] = v / riskAssessment.TotalFunds
	}

	// 3. è®¡ç®—éœ€è¦çš„è½¬ç§»æ“ä½œ
	requiredTransfers := rs.calculateRequiredTransfers(currentDistribution, targetDistribution, riskAssessment.TotalFunds)

	// 4. ä¼°ç®—æˆæœ¬å’Œé£é™©é™ä½
	estimatedCost := rs.estimateTransferCosts(requiredTransfers)
	expectedRiskReduction := rs.calculateExpectedRiskReduction(riskAssessment, targetDistribution)

	// 5. ç¡®å®šä¼˜å…ˆçº§
	priority := rs.calculateDistributionPriority(riskAssessment.RiskLevel, expectedRiskReduction)

	distribution := &OptimalFundDistribution{
		TargetDistribution:    targetDistribution,
		CurrentDistribution:   currentDistribution,
		RequiredTransfers:     requiredTransfers,
		ExpectedRiskReduction: expectedRiskReduction,
		EstimatedCost:         estimatedCost,
		Priority:              priority,
		Timestamp:             time.Now(),
	}

	log.Printf("Optimal fund distribution calculated: %d transfers, cost=%.2f, risk reduction=%.4f",
		len(requiredTransfers), estimatedCost, expectedRiskReduction)

	return distribution, nil
}

// calculateTargetDistribution è®¡ç®—ç›®æ ‡åˆ†é…æ¯”ä¾‹
func (rs *RiskScheduler) calculateTargetDistribution(riskAssessment *FundConcentrationRisk) map[string]float64 {
	targetDistribution := make(map[string]float64)

	// åŸºäºé£é™©ç­‰çº§è®¾å®šç›®æ ‡åˆ†é…
	switch riskAssessment.RiskLevel {
	case "CRITICAL", "HIGH":
		// é«˜é£é™©æƒ…å†µï¼šæœ€å¤§åˆ†æ•£
		targetDistribution["cold_wallet"] = 0.6 // 60%å†·é’±åŒ…
		targetDistribution["hot_wallet"] = 0.1  // 10%çƒ­é’±åŒ…
		targetDistribution["binance"] = 0.15    // 15%å¸å®‰
		targetDistribution["okx"] = 0.1         // 10%OKX
		targetDistribution["bybit"] = 0.05      // 5%Bybit
	case "MEDIUM":
		// ä¸­ç­‰é£é™©ï¼šå¹³è¡¡åˆ†é…
		targetDistribution["cold_wallet"] = 0.5 // 50%å†·é’±åŒ…
		targetDistribution["hot_wallet"] = 0.15 // 15%çƒ­é’±åŒ…
		targetDistribution["binance"] = 0.2     // 20%å¸å®‰
		targetDistribution["okx"] = 0.1         // 10%OKX
		targetDistribution["bybit"] = 0.05      // 5%Bybit
	case "LOW", "MINIMAL":
		// ä½é£é™©ï¼šä¿æŒå½“å‰åˆ†é…æˆ–è½»å¾®è°ƒæ•´
		for k, v := range riskAssessment.ExchangeDistribution {
			targetDistribution[k] = v / riskAssessment.TotalFunds
		}
		for k, v := range riskAssessment.WalletDistribution {
			targetDistribution[k] = v / riskAssessment.TotalFunds
		}
	}

	return targetDistribution
}

// calculateRequiredTransfers è®¡ç®—éœ€è¦çš„è½¬ç§»æ“ä½œ
func (rs *RiskScheduler) calculateRequiredTransfers(current, target map[string]float64, totalFunds float64) []*FundTransfer {
	var transfers []*FundTransfer
	transferID := 1

	for location, targetRatio := range target {
		currentRatio := current[location]
		if currentRatio == 0 {
			currentRatio = 0
		}

		difference := targetRatio - currentRatio

		// åªæœ‰å·®å¼‚è¶…è¿‡é˜ˆå€¼æ‰æ‰§è¡Œè½¬ç§»
		if math.Abs(difference) > 0.05 { // 5%é˜ˆå€¼
			amount := math.Abs(difference) * totalFunds

			transfer := &FundTransfer{
				ID:               fmt.Sprintf("transfer_%d_%d", time.Now().Unix(), transferID),
				Amount:           amount,
				Currency:         "USDT",
				Status:           "PENDING",
				EstimatedFee:     amount * 0.001, // 0.1%æ‰‹ç»­è´¹
				RequiredConfirms: 6,
				CreatedAt:        time.Now(),
				Metadata:         make(map[string]interface{}),
			}

			if difference > 0 {
				// éœ€è¦å¢åŠ èµ„é‡‘åˆ°è¿™ä¸ªä½ç½®
				transfer.Type = "DEPOSIT"
				transfer.ToAddress = location
				transfer.FromAddress = rs.findSourceForTransfer(current, target, totalFunds)
				transfer.Priority = rs.calculateTransferPriority(difference, location)
			} else {
				// éœ€è¦ä»è¿™ä¸ªä½ç½®è½¬å‡ºèµ„é‡‘
				transfer.Type = "WITHDRAW"
				transfer.FromAddress = location
				transfer.ToAddress = rs.findDestinationForTransfer(current, target, totalFunds)
				transfer.Priority = rs.calculateTransferPriority(math.Abs(difference), location)
			}

			transfer.Metadata["target_ratio"] = targetRatio
			transfer.Metadata["current_ratio"] = currentRatio
			transfer.Metadata["difference"] = difference

			transfers = append(transfers, transfer)
			transferID++
		}
	}

	// æŒ‰ä¼˜å…ˆçº§æ’åº
	sort.Slice(transfers, func(i, j int) bool {
		return transfers[i].Priority > transfers[j].Priority
	})

	return transfers
}

// è¾…åŠ©æ–¹æ³•å®ç°

// estimateTransferCosts ä¼°ç®—è½¬ç§»æˆæœ¬
func (rs *RiskScheduler) estimateTransferCosts(transfers []*FundTransfer) float64 {
	totalCost := 0.0
	for _, transfer := range transfers {
		totalCost += transfer.EstimatedFee
	}
	return totalCost
}

// calculateExpectedRiskReduction è®¡ç®—é¢„æœŸé£é™©é™ä½
func (rs *RiskScheduler) calculateExpectedRiskReduction(assessment *FundConcentrationRisk, targetDistribution map[string]float64) float64 {
	// è®¡ç®—å½“å‰é£é™©åˆ†æ•°
	currentRisk := assessment.ConcentrationRatio

	// è®¡ç®—ç›®æ ‡é£é™©åˆ†æ•°
	targetRisk := 0.0
	for _, ratio := range targetDistribution {
		if ratio > targetRisk {
			targetRisk = ratio
		}
	}

	return math.Max(0, currentRisk-targetRisk)
}

// calculateDistributionPriority è®¡ç®—åˆ†é…ä¼˜å…ˆçº§
func (rs *RiskScheduler) calculateDistributionPriority(riskLevel string, riskReduction float64) int {
	basePriority := 0
	switch riskLevel {
	case "CRITICAL":
		basePriority = 5
	case "HIGH":
		basePriority = 4
	case "MEDIUM":
		basePriority = 3
	case "LOW":
		basePriority = 2
	default:
		basePriority = 1
	}

	// åŸºäºé£é™©é™ä½ç¨‹åº¦è°ƒæ•´ä¼˜å…ˆçº§
	if riskReduction > 0.3 {
		basePriority += 2
	} else if riskReduction > 0.1 {
		basePriority += 1
	}

	return basePriority
}

// findSourceForTransfer æ‰¾åˆ°è½¬ç§»èµ„é‡‘çš„æ¥æº
func (rs *RiskScheduler) findSourceForTransfer(current, target map[string]float64, totalFunds float64) string {
	// æ‰¾åˆ°è¶…å‡ºç›®æ ‡æ¯”ä¾‹æœ€å¤šçš„ä½ç½®ä½œä¸ºæ¥æº
	maxExcess := 0.0
	sourceLocation := ""

	for location, currentRatio := range current {
		targetRatio := target[location]
		if targetRatio == 0 {
			targetRatio = 0
		}

		excess := currentRatio - targetRatio
		if excess > maxExcess {
			maxExcess = excess
			sourceLocation = location
		}
	}

	if sourceLocation == "" {
		// é»˜è®¤ä»æœ€å¤§çš„ä½ç½®è½¬å‡º
		maxAmount := 0.0
		for location, ratio := range current {
			if ratio > maxAmount {
				maxAmount = ratio
				sourceLocation = location
			}
		}
	}

	return sourceLocation
}

// findDestinationForTransfer æ‰¾åˆ°è½¬ç§»èµ„é‡‘çš„ç›®æ ‡
func (rs *RiskScheduler) findDestinationForTransfer(current, target map[string]float64, totalFunds float64) string {
	// æ‰¾åˆ°ä½äºç›®æ ‡æ¯”ä¾‹æœ€å¤šçš„ä½ç½®ä½œä¸ºç›®æ ‡
	maxDeficit := 0.0
	destLocation := ""

	for location, targetRatio := range target {
		currentRatio := current[location]
		if currentRatio == 0 {
			currentRatio = 0
		}

		deficit := targetRatio - currentRatio
		if deficit > maxDeficit {
			maxDeficit = deficit
			destLocation = location
		}
	}

	if destLocation == "" {
		// é»˜è®¤è½¬åˆ°å†·é’±åŒ…
		destLocation = "cold_wallet"
	}

	return destLocation
}

// calculateTransferPriority è®¡ç®—è½¬ç§»ä¼˜å…ˆçº§
func (rs *RiskScheduler) calculateTransferPriority(difference float64, location string) int {
	priority := 1

	// åŸºäºå·®å¼‚å¤§å°
	if difference > 0.3 {
		priority = 5
	} else if difference > 0.2 {
		priority = 4
	} else if difference > 0.1 {
		priority = 3
	} else if difference > 0.05 {
		priority = 2
	}

	// åŸºäºä½ç½®ç±»å‹è°ƒæ•´ä¼˜å…ˆçº§
	if location == "hot_wallet" {
		priority += 1 // çƒ­é’±åŒ…æ“ä½œä¼˜å…ˆçº§æ›´é«˜
	} else if location == "cold_wallet" {
		priority -= 1 // å†·é’±åŒ…æ“ä½œä¼˜å…ˆçº§è¾ƒä½
	}

	if priority < 1 {
		priority = 1
	}
	return priority
}

// executeFundTransfers æ‰§è¡Œèµ„é‡‘è½¬ç§»æ“ä½œ
func (rs *RiskScheduler) executeFundTransfers(ctx context.Context, distribution *OptimalFundDistribution) ([]*TransferResult, error) {
	var results []*TransferResult

	log.Printf("Executing %d fund transfers", len(distribution.RequiredTransfers))

	for _, transfer := range distribution.RequiredTransfers {
		result := &TransferResult{
			Transfer: transfer,
			Success:  false,
			Metadata: make(map[string]interface{}),
		}

		startTime := time.Now()

		// æ‰§è¡Œè½¬ç§»æ“ä½œ
		err := rs.executeIndividualTransfer(ctx, transfer)
		if err != nil {
			result.Error = err.Error()
			log.Printf("Transfer failed: %s -> %s, amount: %.2f, error: %v",
				transfer.FromAddress, transfer.ToAddress, transfer.Amount, err)
		} else {
			result.Success = true
			result.ActualAmount = transfer.Amount
			log.Printf("Transfer completed: %s -> %s, amount: %.2f",
				transfer.FromAddress, transfer.ToAddress, transfer.Amount)
		}

		result.ExecutionTime = time.Since(startTime)
		results = append(results, result)

		// è®°å½•è½¬ç§»ç»“æœåˆ°æ•°æ®åº“
		err = rs.recordTransferResult(ctx, result)
		if err != nil {
			log.Printf("Failed to record transfer result: %v", err)
		}

		// æ·»åŠ å»¶è¿Ÿä»¥é¿å…è¿‡äºé¢‘ç¹çš„æ“ä½œ
		time.Sleep(time.Second * 2)
	}

	successCount := 0
	for _, result := range results {
		if result.Success {
			successCount++
		}
	}

	log.Printf("Fund transfers completed: %d/%d successful", successCount, len(results))
	return results, nil
}

// executeIndividualTransfer æ‰§è¡Œå•ä¸ªè½¬ç§»æ“ä½œ
func (rs *RiskScheduler) executeIndividualTransfer(ctx context.Context, transfer *FundTransfer) error {
	// æ›´æ–°è½¬ç§»çŠ¶æ€ä¸ºæ‰§è¡Œä¸­
	transfer.Status = "EXECUTING"
	now := time.Now()
	transfer.ExecutedAt = &now

	// æ ¹æ®è½¬ç§»ç±»å‹æ‰§è¡Œä¸åŒçš„æ“ä½œ
	switch transfer.Type {
	case "HOT_TO_COLD":
		return rs.executeHotToColdTransfer(ctx, transfer)
	case "COLD_TO_HOT":
		return rs.executeColdToHotTransfer(ctx, transfer)
	case "EXCHANGE_REBALANCE":
		return rs.executeExchangeRebalance(ctx, transfer)
	case "DEPOSIT":
		return rs.executeDeposit(ctx, transfer)
	case "WITHDRAW":
		return rs.executeWithdraw(ctx, transfer)
	default:
		return fmt.Errorf("unsupported transfer type: %s", transfer.Type)
	}
}

// executeHotToColdTransfer æ‰§è¡Œçƒ­é’±åŒ…åˆ°å†·é’±åŒ…è½¬ç§»
func (rs *RiskScheduler) executeHotToColdTransfer(ctx context.Context, transfer *FundTransfer) error {
	log.Printf("Executing hot to cold transfer: %.2f %s", transfer.Amount, transfer.Currency)

	// è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„é’±åŒ…API
	// ç›®å‰ä½¿ç”¨æ¨¡æ‹Ÿå®ç°

	// æ¨¡æ‹Ÿè½¬ç§»å»¶è¿Ÿ
	time.Sleep(time.Millisecond * 500)

	// ç”Ÿæˆæ¨¡æ‹Ÿäº¤æ˜“å“ˆå¸Œ
	transfer.TransactionHash = fmt.Sprintf("0x%x", time.Now().UnixNano())
	transfer.Confirmations = 0
	transfer.Status = "CONFIRMING"

	// æ¨¡æ‹Ÿç¡®è®¤è¿‡ç¨‹
	go rs.simulateConfirmationProcess(transfer)

	return nil
}

// executeColdToHotTransfer æ‰§è¡Œå†·é’±åŒ…åˆ°çƒ­é’±åŒ…è½¬ç§»
func (rs *RiskScheduler) executeColdToHotTransfer(ctx context.Context, transfer *FundTransfer) error {
	log.Printf("Executing cold to hot transfer: %.2f %s", transfer.Amount, transfer.Currency)

	// å†·é’±åŒ…è½¬ç§»éœ€è¦æ›´å¤šçš„å®‰å…¨éªŒè¯
	// è¿™é‡Œåº”è¯¥å®ç°å¤šé‡ç­¾åç­‰å®‰å…¨æœºåˆ¶

	// æ¨¡æ‹Ÿå®‰å…¨éªŒè¯å»¶è¿Ÿ
	time.Sleep(time.Second * 2)

	// ç”Ÿæˆæ¨¡æ‹Ÿäº¤æ˜“å“ˆå¸Œ
	transfer.TransactionHash = fmt.Sprintf("0x%x", time.Now().UnixNano())
	transfer.Confirmations = 0
	transfer.Status = "CONFIRMING"

	// æ¨¡æ‹Ÿç¡®è®¤è¿‡ç¨‹
	go rs.simulateConfirmationProcess(transfer)

	return nil
}

// executeExchangeRebalance æ‰§è¡Œäº¤æ˜“æ‰€é—´å†å¹³è¡¡
func (rs *RiskScheduler) executeExchangeRebalance(ctx context.Context, transfer *FundTransfer) error {
	log.Printf("Executing exchange rebalance: %s -> %s, %.2f %s",
		transfer.FromAddress, transfer.ToAddress, transfer.Amount, transfer.Currency)

	// è¿™é‡Œåº”è¯¥è°ƒç”¨äº¤æ˜“æ‰€APIè¿›è¡Œè½¬ç§»
	// ç›®å‰ä½¿ç”¨æ¨¡æ‹Ÿå®ç°

	// æ¨¡æ‹ŸAPIè°ƒç”¨å»¶è¿Ÿ
	time.Sleep(time.Millisecond * 300)

	// ç”Ÿæˆæ¨¡æ‹Ÿäº¤æ˜“ID
	transfer.TransactionHash = fmt.Sprintf("exchange_transfer_%d", time.Now().UnixNano())
	transfer.Confirmations = transfer.RequiredConfirms // äº¤æ˜“æ‰€å†…éƒ¨è½¬ç§»é€šå¸¸ç«‹å³ç¡®è®¤
	transfer.Status = "COMPLETED"

	now := time.Now()
	transfer.CompletedAt = &now

	return nil
}
