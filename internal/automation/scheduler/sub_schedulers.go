package scheduler

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"math"
	"sort"
	"sync"
	"time"

	"qcat/internal/config"
	"qcat/internal/database"
	"qcat/internal/exchange/account"
	"qcat/internal/hotlist"
	"qcat/internal/monitor"

	"github.com/lib/pq"
)

// RiskScheduler é£é™©è°ƒåº¦å™¨
type RiskScheduler struct {
	config         *config.Config
	db             *database.DB
	accountManager *account.Manager
	isRunning      bool
	mu             sync.RWMutex
}

// NewRiskScheduler åˆ›å»ºé£é™©è°ƒåº¦å™¨
func NewRiskScheduler(cfg *config.Config, db *database.DB, accountManager *account.Manager) *RiskScheduler {
	return &RiskScheduler{
		config:         cfg,
		db:             db,
		accountManager: accountManager,
	}
}

func (rs *RiskScheduler) Start() error {
	rs.mu.Lock()
	defer rs.mu.Unlock()
	rs.isRunning = true
	log.Println("Risk scheduler started")
	return nil
}

func (rs *RiskScheduler) Stop() error {
	rs.mu.Lock()
	defer rs.mu.Unlock()
	rs.isRunning = false
	log.Println("Risk scheduler stopped")
	return nil
}

func (rs *RiskScheduler) HandleMonitoring(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing risk monitoring task: %s", task.Name)

	// TODO: å®ç°é£é™©ç›‘æ§é€»è¾‘
	// 1. æ£€æŸ¥ä¿è¯é‡‘æ¯”ç‡
	// 2. ç›‘æ§ä»“ä½é£é™©
	// 3. æ£€æµ‹å¼‚å¸¸è¡Œæƒ…
	// 4. è§¦å‘é£é™©æ§åˆ¶æªæ–½

	return nil
}

// HandleAbnormalMarketResponse å¤„ç†å¼‚å¸¸è¡Œæƒ…åº”å¯¹ä»»åŠ¡
func (rs *RiskScheduler) HandleAbnormalMarketResponse(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing abnormal market response task: %s", task.Name)

	// å®ç°å¼‚å¸¸è¡Œæƒ…åº”å¯¹é€»è¾‘
	// 1. æ£€æµ‹å¼‚å¸¸è¡Œæƒ…æ¡ä»¶
	// 2. è§¦å‘ç†”æ–­ä¿æŠ¤
	// 3. è‡ªåŠ¨é™æ æ†
	// 4. ç´§æ€¥å¹³ä»“ä¿æŠ¤

	// TODO: å®ç°å®æ—¶å¼‚å¸¸æ£€æµ‹å’Œè‡ªåŠ¨åº”å¯¹æœºåˆ¶
	log.Printf("Abnormal market response logic executed")
	return nil
}

// HandleStopLossAdjustment å¤„ç†æ­¢ç›ˆæ­¢æŸçº¿è‡ªåŠ¨è°ƒæ•´ä»»åŠ¡
func (rs *RiskScheduler) HandleStopLossAdjustment(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing stop loss adjustment task: %s", task.Name)

	// å®ç°æ­¢ç›ˆæ­¢æŸçº¿è‡ªåŠ¨è°ƒæ•´é€»è¾‘
	// 1. åŸºäºATRè®¡ç®—åŠ¨æ€æ­¢æŸçº¿
	// 2. åŸºäºRVè®¡ç®—åŠ¨æ€æ­¢æŸçº¿
	// 3. æ ¹æ®å¸‚åœºçŠ¶æ€è°ƒæ•´å‚æ•°
	// 4. åº”ç”¨æ–°çš„æ­¢æŸè®¾ç½®

	// TODO: å®ç°åŸºäºATR/RVçš„åŠ¨æ€è°ƒæ•´ç®—æ³•
	log.Printf("Stop loss adjustment logic executed")
	return nil
}

// HandleFundDistribution å¤„ç†èµ„é‡‘åˆ†æ•£ä¸è½¬ç§»ä»»åŠ¡
func (rs *RiskScheduler) HandleFundDistribution(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing fund distribution task: %s", task.Name)

	// 1. æ£€æŸ¥èµ„é‡‘é›†ä¸­åº¦é£é™©
	riskAssessment, err := rs.assessFundConcentrationRisk(ctx)
	if err != nil {
		log.Printf("Failed to assess fund concentration risk: %v", err)
		return fmt.Errorf("failed to assess fund concentration risk: %w", err)
	}

	// 2. è®¡ç®—æœ€ä¼˜èµ„é‡‘åˆ†é…
	optimalDistribution, err := rs.calculateOptimalFundDistribution(ctx, riskAssessment)
	if err != nil {
		log.Printf("Failed to calculate optimal fund distribution: %v", err)
		return fmt.Errorf("failed to calculate optimal fund distribution: %w", err)
	}

	// 3. æ‰§è¡Œèµ„é‡‘è½¬ç§»æ“ä½œ
	transferResults, err := rs.executeFundTransfers(ctx, optimalDistribution)
	if err != nil {
		log.Printf("Failed to execute fund transfers: %v", err)
		return fmt.Errorf("failed to execute fund transfers: %w", err)
	}

	// 4. é›†æˆå†·é’±åŒ…åŠŸèƒ½
	err = rs.integrateColdWalletOperations(ctx, transferResults)
	if err != nil {
		log.Printf("Failed to integrate cold wallet operations: %v", err)
		// ä¸è¿”å›é”™è¯¯ï¼Œå› ä¸ºå†·é’±åŒ…æ“ä½œå¤±è´¥ä¸åº”è¯¥å½±å“ä¸»æµç¨‹
	}

	// 5. æ›´æ–°èµ„é‡‘ä¿æŠ¤åè®®
	err = rs.updateFundProtectionProtocol(ctx, optimalDistribution, transferResults)
	if err != nil {
		log.Printf("Failed to update fund protection protocol: %v", err)
		// ä¸è¿”å›é”™è¯¯ï¼Œå› ä¸ºåè®®æ›´æ–°å¤±è´¥ä¸åº”è¯¥å½±å“ä¸»æµç¨‹
	}

	log.Printf("Fund distribution completed successfully. Transferred %d operations", len(transferResults))
	return nil
}

// PositionScheduler ä»“ä½è°ƒåº¦å™¨
type PositionScheduler struct {
	config         *config.Config
	db             *database.DB
	accountManager *account.Manager
	isRunning      bool
	mu             sync.RWMutex
}

// NewPositionScheduler åˆ›å»ºä»“ä½è°ƒåº¦å™¨
func NewPositionScheduler(cfg *config.Config, db *database.DB, accountManager *account.Manager) *PositionScheduler {
	return &PositionScheduler{
		config:         cfg,
		db:             db,
		accountManager: accountManager,
	}
}

func (ps *PositionScheduler) Start() error {
	ps.mu.Lock()
	defer ps.mu.Unlock()
	ps.isRunning = true
	log.Println("Position scheduler started")
	return nil
}

func (ps *PositionScheduler) Stop() error {
	ps.mu.Lock()
	defer ps.mu.Unlock()
	ps.isRunning = false
	log.Println("Position scheduler stopped")
	return nil
}

func (ps *PositionScheduler) HandleOptimization(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing position optimization task: %s", task.Name)

	// TODO: å®ç°ä»“ä½ä¼˜åŒ–é€»è¾‘
	// 1. è·å–å½“å‰ä»“ä½
	// 2. è®¡ç®—æœ€ä¼˜ä»“ä½
	// 3. ç”Ÿæˆè°ƒä»“æŒ‡ä»¤
	// 4. æ‰§è¡Œä»“ä½è°ƒæ•´

	return nil
}

// HandleDynamicFundAllocation å¤„ç†èµ„é‡‘åŠ¨æ€åˆ†é…ä»»åŠ¡
func (ps *PositionScheduler) HandleDynamicFundAllocation(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing dynamic fund allocation task: %s", task.Name)

	// å®ç°èµ„é‡‘åŠ¨æ€åˆ†é…é€»è¾‘
	// 1. åˆ†æå½“å‰èµ„é‡‘ä½¿ç”¨æ•ˆç‡
	// 2. è®¡ç®—æœ€ä¼˜èµ„é‡‘åˆ†é…
	// 3. æ‰§è¡Œèµ„é‡‘é‡æ–°åˆ†é…
	// 4. ç›‘æ§åˆ†é…æ•ˆæœ

	// TODO: å®ç°æ™ºèƒ½èµ„é‡‘åˆ†é…ç®—æ³•
	log.Printf("Dynamic fund allocation logic executed")
	return nil
}

// HandleLayeredPositionManagement å¤„ç†ä»“ä½åˆ†å±‚æœºåˆ¶ä»»åŠ¡
func (ps *PositionScheduler) HandleLayeredPositionManagement(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing layered position management task: %s", task.Name)

	// å®ç°ä»“ä½åˆ†å±‚æœºåˆ¶é€»è¾‘
	// 1. åˆ†æå¸‚åœºæ³¢åŠ¨æ€§
	// 2. è®¡ç®—åˆ†å±‚ä»“ä½é…ç½®
	// 3. æ‰§è¡Œåˆ†å±‚å»ºä»“/å¹³ä»“
	// 4. åŠ¨æ€è°ƒæ•´åˆ†å±‚å‚æ•°

	// TODO: å®ç°å¤šå±‚æ¬¡ä»“ä½ç®¡ç†ç­–ç•¥
	log.Printf("Layered position management logic executed")
	return nil
}

// HandleMultiStrategyHedging å¤„ç†è‡ªåŠ¨åŒ–å¤šç­–ç•¥å¯¹å†²ä»»åŠ¡
func (ps *PositionScheduler) HandleMultiStrategyHedging(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing multi-strategy hedging task: %s", task.Name)

	// 1. åˆ†æç­–ç•¥é—´ç›¸å…³æ€§
	correlationMatrix, err := ps.analyzeStrategyCorrelations(ctx)
	if err != nil {
		log.Printf("Failed to analyze strategy correlations: %v", err)
		return fmt.Errorf("failed to analyze strategy correlations: %w", err)
	}

	// 2. è®¡ç®—åŠ¨æ€å¯¹å†²æ¯”ç‡
	hedgeRatios, err := ps.calculateDynamicHedgeRatios(ctx, correlationMatrix)
	if err != nil {
		log.Printf("Failed to calculate dynamic hedge ratios: %v", err)
		return fmt.Errorf("failed to calculate dynamic hedge ratios: %w", err)
	}

	// 3. æ‰§è¡Œè‡ªåŠ¨å¯¹å†²æ“ä½œ
	hedgeResults, err := ps.executeAutoHedgeOperations(ctx, hedgeRatios)
	if err != nil {
		log.Printf("Failed to execute auto hedge operations: %v", err)
		return fmt.Errorf("failed to execute auto hedge operations: %w", err)
	}

	// 4. ç›‘æ§å¯¹å†²æ•ˆæœ
	err = ps.monitorHedgeEffectiveness(ctx, hedgeResults)
	if err != nil {
		log.Printf("Failed to monitor hedge effectiveness: %v", err)
		// ä¸è¿”å›é”™è¯¯ï¼Œå› ä¸ºç›‘æ§å¤±è´¥ä¸åº”è¯¥å½±å“ä¸»æµç¨‹
	}

	// 5. æ›´æ–°å¯¹å†²å†å²è®°å½•
	err = ps.updateHedgeHistory(ctx, correlationMatrix, hedgeRatios, hedgeResults)
	if err != nil {
		log.Printf("Failed to update hedge history: %v", err)
		// ä¸è¿”å›é”™è¯¯ï¼Œå› ä¸ºè®°å½•å¤±è´¥ä¸åº”è¯¥å½±å“ä¸»æµç¨‹
	}

	log.Printf("Multi-strategy hedging completed successfully. Executed %d hedge operations", len(hedgeResults))
	return nil
}

// DataScheduler æ•°æ®è°ƒåº¦å™¨
type DataScheduler struct {
	config            *config.Config
	db                *database.DB
	isRunning         bool
	mu                sync.RWMutex
	integratedService *hotlist.IntegratedService
}

// NewDataScheduler åˆ›å»ºæ•°æ®è°ƒåº¦å™¨
func NewDataScheduler(cfg *config.Config, db *database.DB) *DataScheduler {
	// åˆ›å»ºé›†æˆæœåŠ¡
	integratedService := hotlist.NewIntegratedService(cfg, db)

	return &DataScheduler{
		config:            cfg,
		db:                db,
		integratedService: integratedService,
	}
}

func (ds *DataScheduler) Start() error {
	ds.mu.Lock()
	defer ds.mu.Unlock()
	ds.isRunning = true
	log.Println("Data scheduler started")
	return nil
}

func (ds *DataScheduler) Stop() error {
	ds.mu.Lock()
	defer ds.mu.Unlock()
	ds.isRunning = false
	log.Println("Data scheduler stopped")
	return nil
}

func (ds *DataScheduler) HandleCleaning(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing data cleaning task: %s", task.Name)

	// TODO: å®ç°æ•°æ®æ¸…æ´—é€»è¾‘
	// 1. æ£€æµ‹å¼‚å¸¸æ•°æ®
	// 2. æ¸…æ´—æ— æ•ˆæ•°æ®
	// 3. æ ¡æ­£æ•°æ®æ ¼å¼
	// 4. æ›´æ–°æ•°æ®è´¨é‡æŒ‡æ ‡

	return nil
}

// HandleAutoBacktesting å¤„ç†è‡ªåŠ¨å›æµ‹ä¸å‰æµ‹ä»»åŠ¡
func (ds *DataScheduler) HandleAutoBacktesting(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing auto backtesting task: %s", task.Name)

	// å®ç°è‡ªåŠ¨å›æµ‹ä¸å‰æµ‹é€»è¾‘
	// 1. è‡ªåŠ¨ç”Ÿæˆå›æµ‹å‚æ•°
	// 2. æ‰§è¡Œå†å²æ•°æ®å›æµ‹
	// 3. æ‰§è¡Œå‰ç»æ€§æµ‹è¯•
	// 4. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š

	// TODO: å®ç°è‡ªåŠ¨åŒ–å›æµ‹å¼•æ“
	log.Printf("Auto backtesting logic executed")
	return nil
}

// HandleHotCoinRecommendation å¤„ç†çƒ­é—¨å¸ç§æ¨èä»»åŠ¡
func (ds *DataScheduler) HandleHotCoinRecommendation(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing hot coin recommendation task: %s", task.Name)

	// å¯åŠ¨é›†æˆæœåŠ¡ï¼ˆå¦‚æœå°šæœªå¯åŠ¨ï¼‰
	if !ds.isServiceRunning() {
		err := ds.integratedService.Start(ctx)
		if err != nil {
			log.Printf("Failed to start integrated service: %v", err)
			return fmt.Errorf("failed to start integrated service: %w", err)
		}
	}

	// å¼ºåˆ¶æ›´æ–°æ¨è
	err := ds.integratedService.ForceUpdate(ctx)
	if err != nil {
		log.Printf("Failed to force update recommendations: %v", err)
		return fmt.Errorf("failed to force update recommendations: %w", err)
	}

	// è·å–æ¨èç»“æœ
	recommendations := ds.integratedService.GetRecommendations()

	// å‘é€æ¨èé€šçŸ¥
	err = ds.sendRecommendationNotifications(ctx, recommendations)
	if err != nil {
		log.Printf("Failed to send recommendation notifications: %v", err)
		// ä¸è¿”å›é”™è¯¯ï¼Œå› ä¸ºé€šçŸ¥å¤±è´¥ä¸åº”è¯¥å½±å“ä¸»æµç¨‹
	}

	log.Printf("Hot coin recommendation completed successfully. Generated %d recommendations", len(recommendations))
	return nil
}

// isServiceRunning æ£€æŸ¥é›†æˆæœåŠ¡æ˜¯å¦è¿è¡Œ
func (ds *DataScheduler) isServiceRunning() bool {
	status := ds.integratedService.GetStatus()
	if running, ok := status["is_running"].(bool); ok {
		return running
	}
	return false
}

// HandleFactorLibraryUpdate å¤„ç†å› å­åº“åŠ¨æ€æ›´æ–°ä»»åŠ¡
func (ds *DataScheduler) HandleFactorLibraryUpdate(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing factor library update task: %s", task.Name)

	// å®ç°å› å­åº“åŠ¨æ€æ›´æ–°é€»è¾‘
	// 1. æ‰«ææ–°çš„å¸‚åœºå› å­
	// 2. è¯„ä¼°å› å­æœ‰æ•ˆæ€§
	// 3. æ›´æ–°å› å­åº“
	// 4. æ¸…ç†è¿‡æœŸå› å­

	// TODO: å®ç°åŠ¨æ€å› å­å‘ç°å’Œè‡ªåŠ¨æ›´æ–°æœºåˆ¶
	log.Printf("Factor library update logic executed")
	return nil
}

// HandleMarketPatternRecognition å¤„ç†å¸‚åœºæ¨¡å¼è¯†åˆ«ä»»åŠ¡
func (ds *DataScheduler) HandleMarketPatternRecognition(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing market pattern recognition task: %s", task.Name)

	// å®ç°å¸‚åœºæ¨¡å¼è¯†åˆ«é€»è¾‘
	// 1. åˆ†æå½“å‰å¸‚åœºçŠ¶æ€
	// 2. è¯†åˆ«å¸‚åœºæ¨¡å¼å˜åŒ–
	// 3. è§¦å‘ç­–ç•¥åˆ‡æ¢
	// 4. æ›´æ–°æ¨¡å¼è¯†åˆ«æ¨¡å‹

	// TODO: å®ç°å®æ—¶æ¨¡å¼è¯†åˆ«ç®—æ³•
	log.Printf("Market pattern recognition logic executed")
	return nil
}

// SystemScheduler ç³»ç»Ÿè°ƒåº¦å™¨
type SystemScheduler struct {
	config    *config.Config
	db        *database.DB
	metrics   *monitor.MetricsCollector
	isRunning bool
	mu        sync.RWMutex
}

// NewSystemScheduler åˆ›å»ºç³»ç»Ÿè°ƒåº¦å™¨
func NewSystemScheduler(cfg *config.Config, db *database.DB, metrics *monitor.MetricsCollector) *SystemScheduler {
	return &SystemScheduler{
		config:  cfg,
		db:      db,
		metrics: metrics,
	}
}

func (ss *SystemScheduler) Start() error {
	ss.mu.Lock()
	defer ss.mu.Unlock()
	ss.isRunning = true
	log.Println("System scheduler started")
	return nil
}

func (ss *SystemScheduler) Stop() error {
	ss.mu.Lock()
	defer ss.mu.Unlock()
	ss.isRunning = false
	log.Println("System scheduler stopped")
	return nil
}

func (ss *SystemScheduler) HandleHealthCheck(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing system health check task: %s", task.Name)

	// TODO: å®ç°ç³»ç»Ÿå¥åº·æ£€æŸ¥é€»è¾‘
	// 1. æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨ç‡
	// 2. ç›‘æ§æœåŠ¡çŠ¶æ€
	// 3. æ£€æµ‹å¼‚å¸¸æƒ…å†µ
	// 4. è§¦å‘è‡ªæ„ˆæœºåˆ¶

	return nil
}

// HandleAccountSecurityMonitoring å¤„ç†è´¦æˆ·å®‰å…¨ç›‘æ§ä»»åŠ¡
func (ss *SystemScheduler) HandleAccountSecurityMonitoring(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing account security monitoring task: %s", task.Name)

	// å®ç°è´¦æˆ·å®‰å…¨ç›‘æ§é€»è¾‘
	// 1. ç›‘æ§å¼‚å¸¸ç™»å½•è¡Œä¸º
	// 2. æ£€æµ‹APIå¯†é’¥å¼‚å¸¸ä½¿ç”¨
	// 3. åˆ†æäº¤æ˜“è¡Œä¸ºæ¨¡å¼
	// 4. è§¦å‘å®‰å…¨å‘Šè­¦

	// TODO: å®ç°æ™ºèƒ½å®‰å…¨ç›‘æ§ç³»ç»Ÿ
	log.Printf("Account security monitoring logic executed")
	return nil
}

// HandleMultiExchangeRedundancy å¤„ç†å¤šäº¤æ˜“æ‰€å†—ä½™ä»»åŠ¡
func (ss *SystemScheduler) HandleMultiExchangeRedundancy(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing multi-exchange redundancy task: %s", task.Name)

	// å®ç°å¤šäº¤æ˜“æ‰€å†—ä½™é€»è¾‘
	// 1. æ£€æŸ¥äº¤æ˜“æ‰€è¿æ¥çŠ¶æ€
	// 2. ç›‘æ§äº¤æ˜“æ‰€æ€§èƒ½
	// 3. è‡ªåŠ¨åˆ‡æ¢æ•…éšœäº¤æ˜“æ‰€
	// 4. ç»´æŠ¤å†—ä½™è¿æ¥

	// TODO: å®ç°äº¤æ˜“æ‰€æ•…éšœè‡ªåŠ¨åˆ‡æ¢æœºåˆ¶
	log.Printf("Multi-exchange redundancy logic executed")
	return nil
}

// HandleAuditLogging å¤„ç†æ—¥å¿—ä¸å®¡è®¡è¿½è¸ªä»»åŠ¡
func (ss *SystemScheduler) HandleAuditLogging(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing audit logging task: %s", task.Name)

	// å®ç°æ—¥å¿—ä¸å®¡è®¡è¿½è¸ªé€»è¾‘
	// 1. æ”¶é›†ç³»ç»Ÿæ“ä½œæ—¥å¿—
	// 2. ç”Ÿæˆå®¡è®¡æŠ¥å‘Š
	// 3. æ£€æŸ¥æ—¥å¿—å®Œæ•´æ€§
	// 4. æ¸…ç†è¿‡æœŸæ—¥å¿—

	// TODO: å®ç°è‡ªåŠ¨åŒ–å®¡è®¡ç³»ç»Ÿ
	log.Printf("Audit logging logic executed")
	return nil
}

// LearningScheduler å­¦ä¹ è°ƒåº¦å™¨
type LearningScheduler struct {
	config    *config.Config
	db        *database.DB
	isRunning bool
	mu        sync.RWMutex
}

// NewLearningScheduler åˆ›å»ºå­¦ä¹ è°ƒåº¦å™¨
func NewLearningScheduler(cfg *config.Config, db *database.DB) *LearningScheduler {
	return &LearningScheduler{
		config: cfg,
		db:     db,
	}
}

func (ls *LearningScheduler) Start() error {
	ls.mu.Lock()
	defer ls.mu.Unlock()
	ls.isRunning = true
	log.Println("Learning scheduler started")
	return nil
}

func (ls *LearningScheduler) Stop() error {
	ls.mu.Lock()
	defer ls.mu.Unlock()
	ls.isRunning = false
	log.Println("Learning scheduler stopped")
	return nil
}

func (ls *LearningScheduler) HandleLearning(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing learning task: %s", task.Name)

	// TODO: å®ç°æœºå™¨å­¦ä¹ é€»è¾‘
	// 1. æ”¶é›†è®­ç»ƒæ•°æ®
	// 2. è®­ç»ƒæ¨¡å‹
	// 3. è¯„ä¼°æ¨¡å‹æ€§èƒ½
	// 4. æ›´æ–°ç­–ç•¥å‚æ•°

	return nil
}

// HandleAutoMLLearning å¤„ç†ç­–ç•¥è‡ªå­¦ä¹ AutoMLä»»åŠ¡
func (ls *LearningScheduler) HandleAutoMLLearning(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing AutoML learning task: %s", task.Name)

	// å®ç°AutoMLå­¦ä¹ é€»è¾‘
	// 1. è‡ªåŠ¨æ¨¡å‹é€‰æ‹©
	// 2. è¶…å‚æ•°ä¼˜åŒ–
	// 3. ç‰¹å¾å·¥ç¨‹
	// 4. æ¨¡å‹é›†æˆ

	// TODO: å®ç°è‡ªåŠ¨æ¨¡å‹é€‰æ‹©ç®—æ³•
	log.Printf("AutoML learning logic executed")
	return nil
}

// HandleGeneticEvolution å¤„ç†é—ä¼ æ·˜æ±°åˆ¶å‡çº§ä»»åŠ¡
func (ls *LearningScheduler) HandleGeneticEvolution(ctx context.Context, task *ScheduledTask) error {
	log.Printf("Executing genetic evolution task: %s", task.Name)

	// å®ç°é—ä¼ æ·˜æ±°åˆ¶å‡çº§é€»è¾‘
	// 1. ç­–ç•¥åŸºå› ç¼–ç 
	// 2. æ‰§è¡Œå˜å¼‚æ“ä½œ
	// 3. é€‚åº”åº¦è¯„ä¼°
	// 4. é€‰æ‹©å’Œç¹æ®–

	// TODO: å®ç°è‡ªåŠ¨å˜å¼‚æœºåˆ¶
	log.Printf("Genetic evolution logic executed")
	return nil
}

// çƒ­é—¨å¸ç§æ¨èç›¸å…³æ•°æ®ç»“æ„

// MarketData å¸‚åœºæ•°æ®
type MarketData struct {
	Symbol          string
	Price           float64
	Volume24h       float64
	VolumeChange24h float64
	PriceChange24h  float64
	Volatility      float64
	FundingRate     float64
	OpenInterest    float64
	OIChange24h     float64
	Timestamp       time.Time
}

// HotScore çƒ­åº¦è¯„åˆ†
type HotScore struct {
	Symbol       string
	TotalScore   float64
	VolumeScore  float64
	PriceScore   float64
	FundingScore float64
	OIScore      float64
	TrendScore   float64
	RiskLevel    string
	Timestamp    time.Time
}

// Recommendation æ¨èç»“æœ
type Recommendation struct {
	Symbol          string
	Score           float64
	RiskLevel       string
	PriceRange      [2]float64 // [min, max]
	SafeLeverage    float64
	MarketSentiment string
	Reason          string
	Timestamp       time.Time
}

// çƒ­é—¨å¸ç§æ¨èç›¸å…³æ–¹æ³•

// getAvailableSymbols è·å–æ‰€æœ‰å¯ç”¨çš„äº¤æ˜“å¯¹
func (ds *DataScheduler) getAvailableSymbols(ctx context.Context) ([]string, error) {
	// ä»æ•°æ®åº“è·å–æ´»è·ƒçš„äº¤æ˜“å¯¹
	query := `
		SELECT DISTINCT symbol
		FROM market_data
		WHERE updated_at > NOW() - INTERVAL '1 hour'
		AND volume_24h > 1000000  -- æœ€å°äº¤æ˜“é‡è¿‡æ»¤
		ORDER BY symbol
	`

	rows, err := ds.db.QueryContext(ctx, query)
	if err != nil {
		return nil, fmt.Errorf("failed to query symbols: %w", err)
	}
	defer rows.Close()

	var symbols []string
	for rows.Next() {
		var symbol string
		if err := rows.Scan(&symbol); err != nil {
			return nil, fmt.Errorf("failed to scan symbol: %w", err)
		}
		symbols = append(symbols, symbol)
	}

	// å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤çš„çƒ­é—¨å¸ç§åˆ—è¡¨
	if len(symbols) == 0 {
		symbols = []string{
			"BTCUSDT", "ETHUSDT", "BNBUSDT", "ADAUSDT", "SOLUSDT",
			"XRPUSDT", "DOTUSDT", "DOGEUSDT", "AVAXUSDT", "MATICUSDT",
			"LINKUSDT", "LTCUSDT", "UNIUSDT", "ATOMUSDT", "FILUSDT",
		}
	}

	return symbols, nil
}

// collectMarketData æ”¶é›†å¸‚åœºæ•°æ®
func (ds *DataScheduler) collectMarketData(ctx context.Context, symbols []string) ([]*MarketData, error) {
	var marketData []*MarketData

	for _, symbol := range symbols {
		// ä»æ•°æ®åº“è·å–æœ€æ–°çš„å¸‚åœºæ•°æ®
		query := `
			SELECT
				symbol,
				price,
				volume_24h,
				volume_change_24h,
				price_change_24h,
				volatility,
				funding_rate,
				open_interest,
				oi_change_24h,
				updated_at
			FROM market_data
			WHERE symbol = $1
			ORDER BY updated_at DESC
			LIMIT 1
		`

		var data MarketData
		err := ds.db.QueryRowContext(ctx, query, symbol).Scan(
			&data.Symbol,
			&data.Price,
			&data.Volume24h,
			&data.VolumeChange24h,
			&data.PriceChange24h,
			&data.Volatility,
			&data.FundingRate,
			&data.OpenInterest,
			&data.OIChange24h,
			&data.Timestamp,
		)

		if err != nil {
			// å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ç”¨äºæµ‹è¯•
			log.Printf("No market data found for %s, using mock data: %v", symbol, err)
			data = MarketData{
				Symbol:          symbol,
				Price:           50000.0 + float64(len(symbol)*1000), // æ¨¡æ‹Ÿä»·æ ¼
				Volume24h:       1000000.0 + float64(len(symbol)*100000),
				VolumeChange24h: -10.0 + float64(len(symbol)%20),
				PriceChange24h:  -5.0 + float64(len(symbol)%10),
				Volatility:      0.02 + float64(len(symbol)%5)*0.01,
				FundingRate:     0.0001 + float64(len(symbol)%3)*0.0001,
				OpenInterest:    500000.0 + float64(len(symbol)*50000),
				OIChange24h:     -5.0 + float64(len(symbol)%10),
				Timestamp:       time.Now(),
			}
		}

		marketData = append(marketData, &data)
	}

	return marketData, nil
}

// analyzeHotness åˆ†æçƒ­åº¦æŒ‡æ ‡
func (ds *DataScheduler) analyzeHotness(ctx context.Context, marketData []*MarketData) ([]*HotScore, error) {
	var hotScores []*HotScore

	for _, data := range marketData {
		score := &HotScore{
			Symbol:    data.Symbol,
			Timestamp: time.Now(),
		}

		// 1. äº¤æ˜“é‡è¯„åˆ† (0-30åˆ†)
		volumeScore := ds.calculateVolumeScore(data)
		score.VolumeScore = volumeScore

		// 2. ä»·æ ¼å˜åŠ¨è¯„åˆ† (0-25åˆ†)
		priceScore := ds.calculatePriceScore(data)
		score.PriceScore = priceScore

		// 3. èµ„é‡‘è´¹ç‡è¯„åˆ† (0-20åˆ†)
		fundingScore := ds.calculateFundingScore(data)
		score.FundingScore = fundingScore

		// 4. æŒä»“é‡è¯„åˆ† (0-15åˆ†)
		oiScore := ds.calculateOIScore(data)
		score.OIScore = oiScore

		// 5. è¶‹åŠ¿è¯„åˆ† (0-10åˆ†)
		trendScore := ds.calculateTrendScore(data)
		score.TrendScore = trendScore

		// è®¡ç®—æ€»åˆ†
		score.TotalScore = volumeScore + priceScore + fundingScore + oiScore + trendScore

		// ç¡®å®šé£é™©ç­‰çº§
		score.RiskLevel = ds.determineRiskLevel(score.TotalScore, data)

		hotScores = append(hotScores, score)
	}

	// æŒ‰æ€»åˆ†æ’åº
	sort.Slice(hotScores, func(i, j int) bool {
		return hotScores[i].TotalScore > hotScores[j].TotalScore
	})

	return hotScores, nil
}

// calculateVolumeScore è®¡ç®—äº¤æ˜“é‡è¯„åˆ†
func (ds *DataScheduler) calculateVolumeScore(data *MarketData) float64 {
	// åŸºç¡€äº¤æ˜“é‡è¯„åˆ† (0-15åˆ†)
	baseScore := math.Min(15, math.Log10(data.Volume24h/1000000)*5)
	if baseScore < 0 {
		baseScore = 0
	}

	// äº¤æ˜“é‡å˜åŒ–è¯„åˆ† (0-15åˆ†)
	changeScore := math.Min(15, math.Max(0, data.VolumeChange24h/10))

	return baseScore + changeScore
}

// calculatePriceScore è®¡ç®—ä»·æ ¼å˜åŠ¨è¯„åˆ†
func (ds *DataScheduler) calculatePriceScore(data *MarketData) float64 {
	// ä»·æ ¼å˜åŒ–å¹…åº¦è¯„åˆ† (0-15åˆ†)
	changeScore := math.Min(15, math.Abs(data.PriceChange24h)/2)

	// æ³¢åŠ¨ç‡è¯„åˆ† (0-10åˆ†)
	volatilityScore := math.Min(10, data.Volatility*200)

	return changeScore + volatilityScore
}

// calculateFundingScore è®¡ç®—èµ„é‡‘è´¹ç‡è¯„åˆ†
func (ds *DataScheduler) calculateFundingScore(data *MarketData) float64 {
	// èµ„é‡‘è´¹ç‡å¼‚å¸¸ç¨‹åº¦è¯„åˆ†
	absRate := math.Abs(data.FundingRate)

	// æ­£å¸¸èµ„é‡‘è´¹ç‡èŒƒå›´æ˜¯ -0.01% åˆ° 0.01%
	if absRate > 0.001 {
		return math.Min(20, absRate*10000) // è¶…å‡ºæ­£å¸¸èŒƒå›´ç»™é«˜åˆ†
	}

	return absRate * 5000 // æ­£å¸¸èŒƒå›´å†…ç»™è¾ƒä½åˆ†
}

// calculateOIScore è®¡ç®—æŒä»“é‡è¯„åˆ†
func (ds *DataScheduler) calculateOIScore(data *MarketData) float64 {
	// æŒä»“é‡å˜åŒ–è¯„åˆ†
	changeScore := math.Min(15, math.Max(0, math.Abs(data.OIChange24h)/5))

	return changeScore
}

// calculateTrendScore è®¡ç®—è¶‹åŠ¿è¯„åˆ†
func (ds *DataScheduler) calculateTrendScore(data *MarketData) float64 {
	// åŸºäºä»·æ ¼å˜åŒ–å’Œäº¤æ˜“é‡å˜åŒ–çš„è¶‹åŠ¿å¼ºåº¦
	priceWeight := math.Abs(data.PriceChange24h) / 10
	volumeWeight := data.VolumeChange24h / 20

	trendStrength := (priceWeight + volumeWeight) / 2
	return math.Min(10, math.Max(0, trendStrength))
}

// determineRiskLevel ç¡®å®šé£é™©ç­‰çº§
func (ds *DataScheduler) determineRiskLevel(totalScore float64, data *MarketData) string {
	// åŸºäºæ€»åˆ†å’Œæ³¢åŠ¨ç‡ç¡®å®šé£é™©ç­‰çº§
	if totalScore >= 80 || data.Volatility > 0.1 {
		return "HIGH"
	} else if totalScore >= 60 || data.Volatility > 0.05 {
		return "MEDIUM"
	} else {
		return "LOW"
	}
}

// generateRecommendations ç”Ÿæˆæ¨èåˆ—è¡¨
func (ds *DataScheduler) generateRecommendations(ctx context.Context, hotScores []*HotScore) ([]*Recommendation, error) {
	// è½¬æ¢ä¸ºç¬¦å·åˆ—è¡¨
	symbols := make([]string, len(hotScores))
	for i, score := range hotScores {
		symbols[i] = score.Symbol
	}

	// ä½¿ç”¨é›†æˆæœåŠ¡ç”Ÿæˆæ¨è
	enhancedRecs := ds.integratedService.GetRecommendations()
	if len(enhancedRecs) == 0 {
		// å¦‚æœæ²¡æœ‰ç¼“å­˜çš„æ¨èï¼Œå¼ºåˆ¶æ›´æ–°
		err := ds.integratedService.ForceUpdate(ctx)
		if err != nil {
			return nil, fmt.Errorf("failed to force update recommendations: %w", err)
		}
		enhancedRecs = ds.integratedService.GetRecommendations()
	}

	// è½¬æ¢ä¸ºæ—§æ ¼å¼ä»¥ä¿æŒå…¼å®¹æ€§
	var recommendations []*Recommendation
	for _, enhancedRec := range enhancedRecs {
		recommendation := &Recommendation{
			Symbol:          enhancedRec.Symbol,
			Score:           enhancedRec.Score,
			RiskLevel:       enhancedRec.RiskLevel,
			PriceRange:      enhancedRec.PriceRange,
			SafeLeverage:    enhancedRec.SafeLeverage,
			MarketSentiment: enhancedRec.MarketSentiment,
			Reason:          enhancedRec.Reason,
			Timestamp:       enhancedRec.Timestamp,
		}
		recommendations = append(recommendations, recommendation)
	}

	return recommendations, nil
}

// calculateSafeLeverage è®¡ç®—å®‰å…¨æ æ†å€æ•°
func (ds *DataScheduler) calculateSafeLeverage(riskLevel string) float64 {
	switch riskLevel {
	case "HIGH":
		return 2.0 // é«˜é£é™©å¸ç§å»ºè®®ä½æ æ†
	case "MEDIUM":
		return 5.0 // ä¸­é£é™©å¸ç§å»ºè®®ä¸­ç­‰æ æ†
	case "LOW":
		return 10.0 // ä½é£é™©å¸ç§å¯ä»¥ä½¿ç”¨è¾ƒé«˜æ æ†
	default:
		return 1.0 // é»˜è®¤æ— æ æ†
	}
}

// determineMarketSentiment ç¡®å®šå¸‚åœºæƒ…ç»ª
func (ds *DataScheduler) determineMarketSentiment(score *HotScore) string {
	if score.TotalScore >= 80 {
		return "EXTREMELY_BULLISH"
	} else if score.TotalScore >= 70 {
		return "BULLISH"
	} else if score.TotalScore >= 60 {
		return "NEUTRAL_BULLISH"
	} else if score.TotalScore >= 50 {
		return "NEUTRAL"
	} else {
		return "BEARISH"
	}
}

// generateRecommendationReason ç”Ÿæˆæ¨èç†ç”±
func (ds *DataScheduler) generateRecommendationReason(score *HotScore) string {
	reasons := []string{}

	if score.VolumeScore > 20 {
		reasons = append(reasons, "äº¤æ˜“é‡å¼‚å¸¸æ´»è·ƒ")
	}
	if score.PriceScore > 15 {
		reasons = append(reasons, "ä»·æ ¼æ³¢åŠ¨æ˜¾è‘—")
	}
	if score.FundingScore > 10 {
		reasons = append(reasons, "èµ„é‡‘è´¹ç‡å¼‚å¸¸")
	}
	if score.OIScore > 8 {
		reasons = append(reasons, "æŒä»“é‡å˜åŒ–æ˜æ˜¾")
	}
	if score.TrendScore > 6 {
		reasons = append(reasons, "è¶‹åŠ¿å¼ºåŠ²")
	}

	if len(reasons) == 0 {
		return "ç»¼åˆæŒ‡æ ‡è¡¨ç°è‰¯å¥½"
	}

	result := "æ¨èç†ç”±: "
	for i, reason := range reasons {
		if i > 0 {
			result += ", "
		}
		result += reason
	}

	return result
}

// updateHotlistDatabase æ›´æ–°çƒ­é—¨å¸ç§æ•°æ®åº“
func (ds *DataScheduler) updateHotlistDatabase(ctx context.Context, recommendations []*Recommendation) error {
	// æ¸…ç†æ—§çš„æ¨èæ•°æ® (ä¿ç•™æœ€è¿‘24å°æ—¶çš„æ•°æ®)
	cleanupQuery := `
		DELETE FROM hotlist_recommendations
		WHERE created_at < NOW() - INTERVAL '24 hours'
	`

	_, err := ds.db.ExecContext(ctx, cleanupQuery)
	if err != nil {
		log.Printf("Failed to cleanup old recommendations: %v", err)
		// ä¸è¿”å›é”™è¯¯ï¼Œç»§ç»­æ‰§è¡Œ
	}

	// æ’å…¥æ–°çš„æ¨èæ•°æ®
	insertQuery := `
		INSERT INTO hotlist_recommendations (
			symbol, score, risk_level, price_min, price_max,
			safe_leverage, market_sentiment, reason, created_at
		) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
		ON CONFLICT (symbol) DO UPDATE SET
			score = EXCLUDED.score,
			risk_level = EXCLUDED.risk_level,
			price_min = EXCLUDED.price_min,
			price_max = EXCLUDED.price_max,
			safe_leverage = EXCLUDED.safe_leverage,
			market_sentiment = EXCLUDED.market_sentiment,
			reason = EXCLUDED.reason,
			updated_at = NOW()
	`

	for _, rec := range recommendations {
		_, err := ds.db.ExecContext(ctx, insertQuery,
			rec.Symbol,
			rec.Score,
			rec.RiskLevel,
			rec.PriceRange[0],
			rec.PriceRange[1],
			rec.SafeLeverage,
			rec.MarketSentiment,
			rec.Reason,
			rec.Timestamp,
		)

		if err != nil {
			log.Printf("Failed to insert recommendation for %s: %v", rec.Symbol, err)
			// ç»§ç»­å¤„ç†å…¶ä»–æ¨èï¼Œä¸è¿”å›é”™è¯¯
		}
	}

	log.Printf("Successfully updated %d recommendations in database", len(recommendations))
	return nil
}

// sendRecommendationNotifications å‘é€æ¨èé€šçŸ¥ (æ”¯æŒå¢å¼ºæ¨è)
func (ds *DataScheduler) sendRecommendationNotifications(ctx context.Context, recommendations []*hotlist.EnhancedRecommendation) error {
	// åªé€šçŸ¥é«˜åˆ†æ¨è (åˆ†æ•° >= 75)
	highScoreRecs := []*hotlist.EnhancedRecommendation{}
	for _, rec := range recommendations {
		if rec.Score >= 75 {
			highScoreRecs = append(highScoreRecs, rec)
		}
	}

	if len(highScoreRecs) == 0 {
		log.Printf("No high-score recommendations to notify")
		return nil
	}

	// æ„å»ºé€šçŸ¥æ¶ˆæ¯
	message := fmt.Sprintf("ğŸ”¥ å‘ç° %d ä¸ªçƒ­é—¨å¸ç§æ¨è:\n", len(highScoreRecs))
	for i, rec := range highScoreRecs {
		if i >= 5 { // æœ€å¤šæ˜¾ç¤º5ä¸ª
			break
		}
		message += fmt.Sprintf("â€¢ %s (è¯„åˆ†: %.1f, é£é™©: %s, ç½®ä¿¡åº¦: %.1f%%)\n",
			rec.Symbol, rec.Score, rec.RiskLevel, rec.Confidence*100)
	}

	// è¿™é‡Œå¯ä»¥é›†æˆå®é™…çš„é€šçŸ¥ç³»ç»Ÿ (å¦‚Webhookã€é‚®ä»¶ã€Slackç­‰)
	// ç›®å‰åªè®°å½•æ—¥å¿—
	log.Printf("Notification: %s", message)

	// TODO: å®ç°å®é™…çš„é€šçŸ¥å‘é€é€»è¾‘
	// ä¾‹å¦‚: å‘é€åˆ°Webhookã€é‚®ä»¶ã€Slackç­‰

	return nil
}

// èµ„é‡‘åˆ†æ•£ä¸è½¬ç§»ç›¸å…³æ•°æ®ç»“æ„

// FundConcentrationRisk èµ„é‡‘é›†ä¸­åº¦é£é™©è¯„ä¼°
type FundConcentrationRisk struct {
	TotalFunds           float64            `json:"total_funds"`
	ExchangeDistribution map[string]float64 `json:"exchange_distribution"`
	WalletDistribution   map[string]float64 `json:"wallet_distribution"`
	RiskLevel            string             `json:"risk_level"`
	ConcentrationRatio   float64            `json:"concentration_ratio"`
	RiskFactors          map[string]float64 `json:"risk_factors"`
	Recommendations      []string           `json:"recommendations"`
	Timestamp            time.Time          `json:"timestamp"`
}

// OptimalFundDistribution æœ€ä¼˜èµ„é‡‘åˆ†é…
type OptimalFundDistribution struct {
	TargetDistribution    map[string]float64 `json:"target_distribution"`
	CurrentDistribution   map[string]float64 `json:"current_distribution"`
	RequiredTransfers     []*FundTransfer    `json:"required_transfers"`
	ExpectedRiskReduction float64            `json:"expected_risk_reduction"`
	EstimatedCost         float64            `json:"estimated_cost"`
	Priority              int                `json:"priority"`
	Timestamp             time.Time          `json:"timestamp"`
}

// FundTransfer èµ„é‡‘è½¬ç§»æ“ä½œ
type FundTransfer struct {
	ID               string                 `json:"id"`
	Type             string                 `json:"type"` // HOT_TO_COLD, COLD_TO_HOT, EXCHANGE_REBALANCE
	FromAddress      string                 `json:"from_address"`
	ToAddress        string                 `json:"to_address"`
	Amount           float64                `json:"amount"`
	Currency         string                 `json:"currency"`
	Status           string                 `json:"status"`
	Priority         int                    `json:"priority"`
	EstimatedFee     float64                `json:"estimated_fee"`
	ActualFee        float64                `json:"actual_fee"`
	TransactionHash  string                 `json:"transaction_hash"`
	Confirmations    int                    `json:"confirmations"`
	RequiredConfirms int                    `json:"required_confirms"`
	CreatedAt        time.Time              `json:"created_at"`
	ExecutedAt       *time.Time             `json:"executed_at"`
	CompletedAt      *time.Time             `json:"completed_at"`
	Metadata         map[string]interface{} `json:"metadata"`
}

// TransferResult è½¬ç§»ç»“æœ
type TransferResult struct {
	Transfer      *FundTransfer          `json:"transfer"`
	Success       bool                   `json:"success"`
	Error         string                 `json:"error,omitempty"`
	ActualAmount  float64                `json:"actual_amount"`
	ExecutionTime time.Duration          `json:"execution_time"`
	Metadata      map[string]interface{} `json:"metadata"`
}

// ColdWalletOperation å†·é’±åŒ…æ“ä½œ
type ColdWalletOperation struct {
	ID            string                 `json:"id"`
	Type          string                 `json:"type"` // DEPOSIT, WITHDRAW, BALANCE_CHECK
	WalletAddress string                 `json:"wallet_address"`
	Amount        float64                `json:"amount"`
	Currency      string                 `json:"currency"`
	Status        string                 `json:"status"`
	SecurityLevel string                 `json:"security_level"`
	RequiredSigs  int                    `json:"required_sigs"`
	ProvidedSigs  int                    `json:"provided_sigs"`
	CreatedAt     time.Time              `json:"created_at"`
	ExecutedAt    *time.Time             `json:"executed_at"`
	Metadata      map[string]interface{} `json:"metadata"`
}

// assessFundConcentrationRisk è¯„ä¼°èµ„é‡‘é›†ä¸­åº¦é£é™©
func (rs *RiskScheduler) assessFundConcentrationRisk(ctx context.Context) (*FundConcentrationRisk, error) {
	// 1. è·å–å½“å‰èµ„é‡‘åˆ†å¸ƒ
	exchangeDistribution, err := rs.getExchangeFundDistribution(ctx)
	if err != nil {
		return nil, fmt.Errorf("failed to get exchange fund distribution: %w", err)
	}

	walletDistribution, err := rs.getWalletFundDistribution(ctx)
	if err != nil {
		return nil, fmt.Errorf("failed to get wallet fund distribution: %w", err)
	}

	// 2. è®¡ç®—æ€»èµ„é‡‘
	totalFunds := 0.0
	for _, amount := range exchangeDistribution {
		totalFunds += amount
	}
	for _, amount := range walletDistribution {
		totalFunds += amount
	}

	// 3. è®¡ç®—é›†ä¸­åº¦æ¯”ç‡
	concentrationRatio := rs.calculateConcentrationRatio(exchangeDistribution, walletDistribution)

	// 4. è¯„ä¼°é£é™©å› å­
	riskFactors := rs.calculateRiskFactors(exchangeDistribution, walletDistribution, totalFunds)

	// 5. ç¡®å®šé£é™©ç­‰çº§
	riskLevel := rs.determineRiskLevel(concentrationRatio, riskFactors)

	// 6. ç”Ÿæˆå»ºè®®
	recommendations := rs.generateRiskRecommendations(riskLevel, concentrationRatio, riskFactors)

	assessment := &FundConcentrationRisk{
		TotalFunds:           totalFunds,
		ExchangeDistribution: exchangeDistribution,
		WalletDistribution:   walletDistribution,
		RiskLevel:            riskLevel,
		ConcentrationRatio:   concentrationRatio,
		RiskFactors:          riskFactors,
		Recommendations:      recommendations,
		Timestamp:            time.Now(),
	}

	log.Printf("Fund concentration risk assessment: Level=%s, Ratio=%.4f, Total=%.2f",
		riskLevel, concentrationRatio, totalFunds)

	return assessment, nil
}

// getExchangeFundDistribution è·å–äº¤æ˜“æ‰€èµ„é‡‘åˆ†å¸ƒ
func (rs *RiskScheduler) getExchangeFundDistribution(ctx context.Context) (map[string]float64, error) {
	query := `
		SELECT exchange_name, SUM(balance) as total_balance
		FROM exchange_balances
		WHERE updated_at > NOW() - INTERVAL '1 hour'
		GROUP BY exchange_name
	`

	rows, err := rs.db.QueryContext(ctx, query)
	if err != nil {
		return nil, fmt.Errorf("failed to query exchange balances: %w", err)
	}
	defer rows.Close()

	distribution := make(map[string]float64)
	for rows.Next() {
		var exchangeName string
		var balance float64
		if err := rows.Scan(&exchangeName, &balance); err != nil {
			return nil, fmt.Errorf("failed to scan exchange balance: %w", err)
		}
		distribution[exchangeName] = balance
	}

	// å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
	if len(distribution) == 0 {
		distribution = map[string]float64{
			"binance": 50000.0,
			"okx":     30000.0,
			"bybit":   20000.0,
		}
	}

	return distribution, nil
}

// getWalletFundDistribution è·å–é’±åŒ…èµ„é‡‘åˆ†å¸ƒ
func (rs *RiskScheduler) getWalletFundDistribution(ctx context.Context) (map[string]float64, error) {
	query := `
		SELECT wallet_type, SUM(balance) as total_balance
		FROM wallet_balances
		WHERE updated_at > NOW() - INTERVAL '1 hour'
		GROUP BY wallet_type
	`

	rows, err := rs.db.QueryContext(ctx, query)
	if err != nil {
		return nil, fmt.Errorf("failed to query wallet balances: %w", err)
	}
	defer rows.Close()

	distribution := make(map[string]float64)
	for rows.Next() {
		var walletType string
		var balance float64
		if err := rows.Scan(&walletType, &balance); err != nil {
			return nil, fmt.Errorf("failed to scan wallet balance: %w", err)
		}
		distribution[walletType] = balance
	}

	// å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
	if len(distribution) == 0 {
		distribution = map[string]float64{
			"hot_wallet":  15000.0,
			"cold_wallet": 35000.0,
		}
	}

	return distribution, nil
}

// calculateConcentrationRatio è®¡ç®—é›†ä¸­åº¦æ¯”ç‡
func (rs *RiskScheduler) calculateConcentrationRatio(exchangeDist, walletDist map[string]float64) float64 {
	// è®¡ç®—æœ€å¤§å•ä¸€é›†ä¸­åº¦
	maxConcentration := 0.0
	totalFunds := 0.0

	// è®¡ç®—æ€»èµ„é‡‘
	for _, amount := range exchangeDist {
		totalFunds += amount
	}
	for _, amount := range walletDist {
		totalFunds += amount
	}

	// æ‰¾å‡ºæœ€å¤§å•ä¸€é›†ä¸­åº¦
	for _, amount := range exchangeDist {
		ratio := amount / totalFunds
		if ratio > maxConcentration {
			maxConcentration = ratio
		}
	}
	for _, amount := range walletDist {
		ratio := amount / totalFunds
		if ratio > maxConcentration {
			maxConcentration = ratio
		}
	}

	return maxConcentration
}

// calculateRiskFactors è®¡ç®—é£é™©å› å­
func (rs *RiskScheduler) calculateRiskFactors(exchangeDist, walletDist map[string]float64, totalFunds float64) map[string]float64 {
	riskFactors := make(map[string]float64)

	// 1. äº¤æ˜“æ‰€é›†ä¸­åº¦é£é™©
	exchangeRisk := 0.0
	for _, amount := range exchangeDist {
		ratio := amount / totalFunds
		if ratio > 0.5 { // å•ä¸€äº¤æ˜“æ‰€è¶…è¿‡50%
			exchangeRisk += (ratio - 0.5) * 2.0 // è¶…å‡ºéƒ¨åˆ†åŠ å€è®¡ç®—é£é™©
		}
	}
	riskFactors["exchange_concentration"] = math.Min(1.0, exchangeRisk)

	// 2. çƒ­é’±åŒ…é£é™©
	hotWalletRisk := 0.0
	if hotAmount, exists := walletDist["hot_wallet"]; exists {
		hotRatio := hotAmount / totalFunds
		if hotRatio > 0.2 { // çƒ­é’±åŒ…è¶…è¿‡20%
			hotWalletRisk = (hotRatio - 0.2) * 2.5
		}
	}
	riskFactors["hot_wallet_risk"] = math.Min(1.0, hotWalletRisk)

	// 3. åœ°ç†åˆ†å¸ƒé£é™© (ç®€åŒ–å¤„ç†)
	geoRisk := 0.3 // å‡è®¾ä¸­ç­‰åœ°ç†é£é™©
	riskFactors["geographic_risk"] = geoRisk

	// 4. æµåŠ¨æ€§é£é™©
	liquidityRisk := 0.0
	exchangeCount := len(exchangeDist)
	if exchangeCount < 2 {
		liquidityRisk = 0.8 // åªæœ‰ä¸€ä¸ªäº¤æ˜“æ‰€ï¼ŒæµåŠ¨æ€§é£é™©å¾ˆé«˜
	} else if exchangeCount < 3 {
		liquidityRisk = 0.4 // ä¸¤ä¸ªäº¤æ˜“æ‰€ï¼Œä¸­ç­‰é£é™©
	} else {
		liquidityRisk = 0.1 // ä¸‰ä¸ªä»¥ä¸Šäº¤æ˜“æ‰€ï¼Œä½é£é™©
	}
	riskFactors["liquidity_risk"] = liquidityRisk

	// 5. æŠ€æœ¯é£é™©
	techRisk := 0.2 // å‡è®¾åŸºç¡€æŠ€æœ¯é£é™©
	riskFactors["technical_risk"] = techRisk

	return riskFactors
}

// determineRiskLevel ç¡®å®šé£é™©ç­‰çº§
func (rs *RiskScheduler) determineRiskLevel(concentrationRatio float64, riskFactors map[string]float64) string {
	// è®¡ç®—ç»¼åˆé£é™©åˆ†æ•°
	totalRisk := concentrationRatio * 0.4 // é›†ä¸­åº¦æƒé‡40%

	for factor, value := range riskFactors {
		switch factor {
		case "exchange_concentration":
			totalRisk += value * 0.25 // äº¤æ˜“æ‰€é›†ä¸­åº¦æƒé‡25%
		case "hot_wallet_risk":
			totalRisk += value * 0.15 // çƒ­é’±åŒ…é£é™©æƒé‡15%
		case "geographic_risk":
			totalRisk += value * 0.1 // åœ°ç†é£é™©æƒé‡10%
		case "liquidity_risk":
			totalRisk += value * 0.05 // æµåŠ¨æ€§é£é™©æƒé‡5%
		case "technical_risk":
			totalRisk += value * 0.05 // æŠ€æœ¯é£é™©æƒé‡5%
		}
	}

	// æ ¹æ®æ€»é£é™©åˆ†æ•°ç¡®å®šç­‰çº§
	if totalRisk >= 0.8 {
		return "CRITICAL"
	} else if totalRisk >= 0.6 {
		return "HIGH"
	} else if totalRisk >= 0.4 {
		return "MEDIUM"
	} else if totalRisk >= 0.2 {
		return "LOW"
	} else {
		return "MINIMAL"
	}
}

// generateRiskRecommendations ç”Ÿæˆé£é™©å»ºè®®
func (rs *RiskScheduler) generateRiskRecommendations(riskLevel string, concentrationRatio float64, riskFactors map[string]float64) []string {
	var recommendations []string

	// åŸºäºé£é™©ç­‰çº§çš„é€šç”¨å»ºè®®
	switch riskLevel {
	case "CRITICAL":
		recommendations = append(recommendations, "ç«‹å³æ‰§è¡Œç´§æ€¥èµ„é‡‘åˆ†æ•£æ“ä½œ")
		recommendations = append(recommendations, "æš‚åœå¤§é¢äº¤æ˜“ç›´åˆ°é£é™©é™ä½")
	case "HIGH":
		recommendations = append(recommendations, "åœ¨24å°æ—¶å†…æ‰§è¡Œèµ„é‡‘é‡æ–°åˆ†é…")
		recommendations = append(recommendations, "å¢åŠ å†·é’±åŒ…å­˜å‚¨æ¯”ä¾‹")
	case "MEDIUM":
		recommendations = append(recommendations, "è€ƒè™‘åœ¨ä¸€å‘¨å†…ä¼˜åŒ–èµ„é‡‘åˆ†å¸ƒ")
		recommendations = append(recommendations, "ç›‘æ§äº¤æ˜“æ‰€é£é™©çŠ¶å†µ")
	case "LOW":
		recommendations = append(recommendations, "ä¿æŒå½“å‰åˆ†æ•£ç­–ç•¥")
		recommendations = append(recommendations, "å®šæœŸè¯„ä¼°èµ„é‡‘åˆ†å¸ƒ")
	}

	// åŸºäºå…·ä½“é£é™©å› å­çš„å»ºè®®
	if riskFactors["exchange_concentration"] > 0.6 {
		recommendations = append(recommendations, "å‡å°‘å•ä¸€äº¤æ˜“æ‰€èµ„é‡‘é›†ä¸­åº¦")
		recommendations = append(recommendations, "è€ƒè™‘å¢åŠ æ–°çš„äº¤æ˜“æ‰€")
	}

	if riskFactors["hot_wallet_risk"] > 0.5 {
		recommendations = append(recommendations, "å°†éƒ¨åˆ†çƒ­é’±åŒ…èµ„é‡‘è½¬ç§»åˆ°å†·é’±åŒ…")
		recommendations = append(recommendations, "åŠ å¼ºçƒ­é’±åŒ…å®‰å…¨ç›‘æ§")
	}

	if riskFactors["liquidity_risk"] > 0.6 {
		recommendations = append(recommendations, "å¢åŠ äº¤æ˜“æ‰€æ•°é‡ä»¥æé«˜æµåŠ¨æ€§")
		recommendations = append(recommendations, "å»ºç«‹åº”æ€¥æµåŠ¨æ€§å‚¨å¤‡")
	}

	if concentrationRatio > 0.7 {
		recommendations = append(recommendations, "ç´§æ€¥åˆ†æ•£èµ„é‡‘ï¼Œé™ä½å•ç‚¹é£é™©")
	}

	return recommendations
}

// calculateOptimalFundDistribution è®¡ç®—æœ€ä¼˜èµ„é‡‘åˆ†é…
func (rs *RiskScheduler) calculateOptimalFundDistribution(ctx context.Context, riskAssessment *FundConcentrationRisk) (*OptimalFundDistribution, error) {
	// 1. å®šä¹‰ç›®æ ‡åˆ†é…æ¯”ä¾‹
	targetDistribution := rs.calculateTargetDistribution(riskAssessment)

	// 2. è·å–å½“å‰åˆ†é…
	currentDistribution := make(map[string]float64)
	for k, v := range riskAssessment.ExchangeDistribution {
		currentDistribution[k] = v / riskAssessment.TotalFunds
	}
	for k, v := range riskAssessment.WalletDistribution {
		currentDistribution[k] = v / riskAssessment.TotalFunds
	}

	// 3. è®¡ç®—éœ€è¦çš„è½¬ç§»æ“ä½œ
	requiredTransfers := rs.calculateRequiredTransfers(currentDistribution, targetDistribution, riskAssessment.TotalFunds)

	// 4. ä¼°ç®—æˆæœ¬å’Œé£é™©é™ä½
	estimatedCost := rs.estimateTransferCosts(requiredTransfers)
	expectedRiskReduction := rs.calculateExpectedRiskReduction(riskAssessment, targetDistribution)

	// 5. ç¡®å®šä¼˜å…ˆçº§
	priority := rs.calculateDistributionPriority(riskAssessment.RiskLevel, expectedRiskReduction)

	distribution := &OptimalFundDistribution{
		TargetDistribution:    targetDistribution,
		CurrentDistribution:   currentDistribution,
		RequiredTransfers:     requiredTransfers,
		ExpectedRiskReduction: expectedRiskReduction,
		EstimatedCost:         estimatedCost,
		Priority:              priority,
		Timestamp:             time.Now(),
	}

	log.Printf("Optimal fund distribution calculated: %d transfers, cost=%.2f, risk reduction=%.4f",
		len(requiredTransfers), estimatedCost, expectedRiskReduction)

	return distribution, nil
}

// calculateTargetDistribution è®¡ç®—ç›®æ ‡åˆ†é…æ¯”ä¾‹
func (rs *RiskScheduler) calculateTargetDistribution(riskAssessment *FundConcentrationRisk) map[string]float64 {
	targetDistribution := make(map[string]float64)

	// åŸºäºé£é™©ç­‰çº§è®¾å®šç›®æ ‡åˆ†é…
	switch riskAssessment.RiskLevel {
	case "CRITICAL", "HIGH":
		// é«˜é£é™©æƒ…å†µï¼šæœ€å¤§åˆ†æ•£
		targetDistribution["cold_wallet"] = 0.6 // 60%å†·é’±åŒ…
		targetDistribution["hot_wallet"] = 0.1  // 10%çƒ­é’±åŒ…
		targetDistribution["binance"] = 0.15    // 15%å¸å®‰
		targetDistribution["okx"] = 0.1         // 10%OKX
		targetDistribution["bybit"] = 0.05      // 5%Bybit
	case "MEDIUM":
		// ä¸­ç­‰é£é™©ï¼šå¹³è¡¡åˆ†é…
		targetDistribution["cold_wallet"] = 0.5 // 50%å†·é’±åŒ…
		targetDistribution["hot_wallet"] = 0.15 // 15%çƒ­é’±åŒ…
		targetDistribution["binance"] = 0.2     // 20%å¸å®‰
		targetDistribution["okx"] = 0.1         // 10%OKX
		targetDistribution["bybit"] = 0.05      // 5%Bybit
	case "LOW", "MINIMAL":
		// ä½é£é™©ï¼šä¿æŒå½“å‰åˆ†é…æˆ–è½»å¾®è°ƒæ•´
		for k, v := range riskAssessment.ExchangeDistribution {
			targetDistribution[k] = v / riskAssessment.TotalFunds
		}
		for k, v := range riskAssessment.WalletDistribution {
			targetDistribution[k] = v / riskAssessment.TotalFunds
		}
	}

	return targetDistribution
}

// calculateRequiredTransfers è®¡ç®—éœ€è¦çš„è½¬ç§»æ“ä½œ
func (rs *RiskScheduler) calculateRequiredTransfers(current, target map[string]float64, totalFunds float64) []*FundTransfer {
	var transfers []*FundTransfer
	transferID := 1

	for location, targetRatio := range target {
		currentRatio := current[location]
		if currentRatio == 0 {
			currentRatio = 0
		}

		difference := targetRatio - currentRatio

		// åªæœ‰å·®å¼‚è¶…è¿‡é˜ˆå€¼æ‰æ‰§è¡Œè½¬ç§»
		if math.Abs(difference) > 0.05 { // 5%é˜ˆå€¼
			amount := math.Abs(difference) * totalFunds

			transfer := &FundTransfer{
				ID:               fmt.Sprintf("transfer_%d_%d", time.Now().Unix(), transferID),
				Amount:           amount,
				Currency:         "USDT",
				Status:           "PENDING",
				EstimatedFee:     amount * 0.001, // 0.1%æ‰‹ç»­è´¹
				RequiredConfirms: 6,
				CreatedAt:        time.Now(),
				Metadata:         make(map[string]interface{}),
			}

			if difference > 0 {
				// éœ€è¦å¢åŠ èµ„é‡‘åˆ°è¿™ä¸ªä½ç½®
				transfer.Type = "DEPOSIT"
				transfer.ToAddress = location
				transfer.FromAddress = rs.findSourceForTransfer(current, target, totalFunds)
				transfer.Priority = rs.calculateTransferPriority(difference, location)
			} else {
				// éœ€è¦ä»è¿™ä¸ªä½ç½®è½¬å‡ºèµ„é‡‘
				transfer.Type = "WITHDRAW"
				transfer.FromAddress = location
				transfer.ToAddress = rs.findDestinationForTransfer(current, target, totalFunds)
				transfer.Priority = rs.calculateTransferPriority(math.Abs(difference), location)
			}

			transfer.Metadata["target_ratio"] = targetRatio
			transfer.Metadata["current_ratio"] = currentRatio
			transfer.Metadata["difference"] = difference

			transfers = append(transfers, transfer)
			transferID++
		}
	}

	// æŒ‰ä¼˜å…ˆçº§æ’åº
	sort.Slice(transfers, func(i, j int) bool {
		return transfers[i].Priority > transfers[j].Priority
	})

	return transfers
}

// è¾…åŠ©æ–¹æ³•å®ç°

// estimateTransferCosts ä¼°ç®—è½¬ç§»æˆæœ¬
func (rs *RiskScheduler) estimateTransferCosts(transfers []*FundTransfer) float64 {
	totalCost := 0.0
	for _, transfer := range transfers {
		totalCost += transfer.EstimatedFee
	}
	return totalCost
}

// calculateExpectedRiskReduction è®¡ç®—é¢„æœŸé£é™©é™ä½
func (rs *RiskScheduler) calculateExpectedRiskReduction(assessment *FundConcentrationRisk, targetDistribution map[string]float64) float64 {
	// è®¡ç®—å½“å‰é£é™©åˆ†æ•°
	currentRisk := assessment.ConcentrationRatio

	// è®¡ç®—ç›®æ ‡é£é™©åˆ†æ•°
	targetRisk := 0.0
	for _, ratio := range targetDistribution {
		if ratio > targetRisk {
			targetRisk = ratio
		}
	}

	return math.Max(0, currentRisk-targetRisk)
}

// calculateDistributionPriority è®¡ç®—åˆ†é…ä¼˜å…ˆçº§
func (rs *RiskScheduler) calculateDistributionPriority(riskLevel string, riskReduction float64) int {
	basePriority := 0
	switch riskLevel {
	case "CRITICAL":
		basePriority = 5
	case "HIGH":
		basePriority = 4
	case "MEDIUM":
		basePriority = 3
	case "LOW":
		basePriority = 2
	default:
		basePriority = 1
	}

	// åŸºäºé£é™©é™ä½ç¨‹åº¦è°ƒæ•´ä¼˜å…ˆçº§
	if riskReduction > 0.3 {
		basePriority += 2
	} else if riskReduction > 0.1 {
		basePriority += 1
	}

	return basePriority
}

// findSourceForTransfer æ‰¾åˆ°è½¬ç§»èµ„é‡‘çš„æ¥æº
func (rs *RiskScheduler) findSourceForTransfer(current, target map[string]float64, totalFunds float64) string {
	// æ‰¾åˆ°è¶…å‡ºç›®æ ‡æ¯”ä¾‹æœ€å¤šçš„ä½ç½®ä½œä¸ºæ¥æº
	maxExcess := 0.0
	sourceLocation := ""

	for location, currentRatio := range current {
		targetRatio := target[location]
		if targetRatio == 0 {
			targetRatio = 0
		}

		excess := currentRatio - targetRatio
		if excess > maxExcess {
			maxExcess = excess
			sourceLocation = location
		}
	}

	if sourceLocation == "" {
		// é»˜è®¤ä»æœ€å¤§çš„ä½ç½®è½¬å‡º
		maxAmount := 0.0
		for location, ratio := range current {
			if ratio > maxAmount {
				maxAmount = ratio
				sourceLocation = location
			}
		}
	}

	return sourceLocation
}

// findDestinationForTransfer æ‰¾åˆ°è½¬ç§»èµ„é‡‘çš„ç›®æ ‡
func (rs *RiskScheduler) findDestinationForTransfer(current, target map[string]float64, totalFunds float64) string {
	// æ‰¾åˆ°ä½äºç›®æ ‡æ¯”ä¾‹æœ€å¤šçš„ä½ç½®ä½œä¸ºç›®æ ‡
	maxDeficit := 0.0
	destLocation := ""

	for location, targetRatio := range target {
		currentRatio := current[location]
		if currentRatio == 0 {
			currentRatio = 0
		}

		deficit := targetRatio - currentRatio
		if deficit > maxDeficit {
			maxDeficit = deficit
			destLocation = location
		}
	}

	if destLocation == "" {
		// é»˜è®¤è½¬åˆ°å†·é’±åŒ…
		destLocation = "cold_wallet"
	}

	return destLocation
}

// calculateTransferPriority è®¡ç®—è½¬ç§»ä¼˜å…ˆçº§
func (rs *RiskScheduler) calculateTransferPriority(difference float64, location string) int {
	priority := 1

	// åŸºäºå·®å¼‚å¤§å°
	if difference > 0.3 {
		priority = 5
	} else if difference > 0.2 {
		priority = 4
	} else if difference > 0.1 {
		priority = 3
	} else if difference > 0.05 {
		priority = 2
	}

	// åŸºäºä½ç½®ç±»å‹è°ƒæ•´ä¼˜å…ˆçº§
	if location == "hot_wallet" {
		priority += 1 // çƒ­é’±åŒ…æ“ä½œä¼˜å…ˆçº§æ›´é«˜
	} else if location == "cold_wallet" {
		priority -= 1 // å†·é’±åŒ…æ“ä½œä¼˜å…ˆçº§è¾ƒä½
	}

	if priority < 1 {
		priority = 1
	}
	return priority
}

// executeFundTransfers æ‰§è¡Œèµ„é‡‘è½¬ç§»æ“ä½œ
func (rs *RiskScheduler) executeFundTransfers(ctx context.Context, distribution *OptimalFundDistribution) ([]*TransferResult, error) {
	var results []*TransferResult

	log.Printf("Executing %d fund transfers", len(distribution.RequiredTransfers))

	for _, transfer := range distribution.RequiredTransfers {
		result := &TransferResult{
			Transfer: transfer,
			Success:  false,
			Metadata: make(map[string]interface{}),
		}

		startTime := time.Now()

		// æ‰§è¡Œè½¬ç§»æ“ä½œ
		err := rs.executeIndividualTransfer(ctx, transfer)
		if err != nil {
			result.Error = err.Error()
			log.Printf("Transfer failed: %s -> %s, amount: %.2f, error: %v",
				transfer.FromAddress, transfer.ToAddress, transfer.Amount, err)
		} else {
			result.Success = true
			result.ActualAmount = transfer.Amount
			log.Printf("Transfer completed: %s -> %s, amount: %.2f",
				transfer.FromAddress, transfer.ToAddress, transfer.Amount)
		}

		result.ExecutionTime = time.Since(startTime)
		results = append(results, result)

		// è®°å½•è½¬ç§»ç»“æœåˆ°æ•°æ®åº“
		err = rs.recordTransferResult(ctx, result)
		if err != nil {
			log.Printf("Failed to record transfer result: %v", err)
		}

		// æ·»åŠ å»¶è¿Ÿä»¥é¿å…è¿‡äºé¢‘ç¹çš„æ“ä½œ
		time.Sleep(time.Second * 2)
	}

	successCount := 0
	for _, result := range results {
		if result.Success {
			successCount++
		}
	}

	log.Printf("Fund transfers completed: %d/%d successful", successCount, len(results))
	return results, nil
}

// executeIndividualTransfer æ‰§è¡Œå•ä¸ªè½¬ç§»æ“ä½œ
func (rs *RiskScheduler) executeIndividualTransfer(ctx context.Context, transfer *FundTransfer) error {
	// æ›´æ–°è½¬ç§»çŠ¶æ€ä¸ºæ‰§è¡Œä¸­
	transfer.Status = "EXECUTING"
	now := time.Now()
	transfer.ExecutedAt = &now

	// æ ¹æ®è½¬ç§»ç±»å‹æ‰§è¡Œä¸åŒçš„æ“ä½œ
	switch transfer.Type {
	case "HOT_TO_COLD":
		return rs.executeHotToColdTransfer(ctx, transfer)
	case "COLD_TO_HOT":
		return rs.executeColdToHotTransfer(ctx, transfer)
	case "EXCHANGE_REBALANCE":
		return rs.executeExchangeRebalance(ctx, transfer)
	case "DEPOSIT":
		return rs.executeDeposit(ctx, transfer)
	case "WITHDRAW":
		return rs.executeWithdraw(ctx, transfer)
	default:
		return fmt.Errorf("unsupported transfer type: %s", transfer.Type)
	}
}

// executeHotToColdTransfer æ‰§è¡Œçƒ­é’±åŒ…åˆ°å†·é’±åŒ…è½¬ç§»
func (rs *RiskScheduler) executeHotToColdTransfer(ctx context.Context, transfer *FundTransfer) error {
	log.Printf("Executing hot to cold transfer: %.2f %s", transfer.Amount, transfer.Currency)

	// è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„é’±åŒ…API
	// ç›®å‰ä½¿ç”¨æ¨¡æ‹Ÿå®ç°

	// æ¨¡æ‹Ÿè½¬ç§»å»¶è¿Ÿ
	time.Sleep(time.Millisecond * 500)

	// ç”Ÿæˆæ¨¡æ‹Ÿäº¤æ˜“å“ˆå¸Œ
	transfer.TransactionHash = fmt.Sprintf("0x%x", time.Now().UnixNano())
	transfer.Confirmations = 0
	transfer.Status = "CONFIRMING"

	// æ¨¡æ‹Ÿç¡®è®¤è¿‡ç¨‹
	go rs.simulateConfirmationProcess(transfer)

	return nil
}

// executeColdToHotTransfer æ‰§è¡Œå†·é’±åŒ…åˆ°çƒ­é’±åŒ…è½¬ç§»
func (rs *RiskScheduler) executeColdToHotTransfer(ctx context.Context, transfer *FundTransfer) error {
	log.Printf("Executing cold to hot transfer: %.2f %s", transfer.Amount, transfer.Currency)

	// å†·é’±åŒ…è½¬ç§»éœ€è¦æ›´å¤šçš„å®‰å…¨éªŒè¯
	// è¿™é‡Œåº”è¯¥å®ç°å¤šé‡ç­¾åç­‰å®‰å…¨æœºåˆ¶

	// æ¨¡æ‹Ÿå®‰å…¨éªŒè¯å»¶è¿Ÿ
	time.Sleep(time.Second * 2)

	// ç”Ÿæˆæ¨¡æ‹Ÿäº¤æ˜“å“ˆå¸Œ
	transfer.TransactionHash = fmt.Sprintf("0x%x", time.Now().UnixNano())
	transfer.Confirmations = 0
	transfer.Status = "CONFIRMING"

	// æ¨¡æ‹Ÿç¡®è®¤è¿‡ç¨‹
	go rs.simulateConfirmationProcess(transfer)

	return nil
}

// executeExchangeRebalance æ‰§è¡Œäº¤æ˜“æ‰€é—´å†å¹³è¡¡
func (rs *RiskScheduler) executeExchangeRebalance(ctx context.Context, transfer *FundTransfer) error {
	log.Printf("Executing exchange rebalance: %s -> %s, %.2f %s",
		transfer.FromAddress, transfer.ToAddress, transfer.Amount, transfer.Currency)

	// è¿™é‡Œåº”è¯¥è°ƒç”¨äº¤æ˜“æ‰€APIè¿›è¡Œè½¬ç§»
	// ç›®å‰ä½¿ç”¨æ¨¡æ‹Ÿå®ç°

	// æ¨¡æ‹ŸAPIè°ƒç”¨å»¶è¿Ÿ
	time.Sleep(time.Millisecond * 300)

	// ç”Ÿæˆæ¨¡æ‹Ÿäº¤æ˜“ID
	transfer.TransactionHash = fmt.Sprintf("exchange_transfer_%d", time.Now().UnixNano())
	transfer.Confirmations = transfer.RequiredConfirms // äº¤æ˜“æ‰€å†…éƒ¨è½¬ç§»é€šå¸¸ç«‹å³ç¡®è®¤
	transfer.Status = "COMPLETED"

	now := time.Now()
	transfer.CompletedAt = &now

	return nil
}

// å‰©ä½™çš„è¾…åŠ©æ–¹æ³•

// executeDeposit æ‰§è¡Œå­˜æ¬¾æ“ä½œ
func (rs *RiskScheduler) executeDeposit(ctx context.Context, transfer *FundTransfer) error {
	log.Printf("Executing deposit: %.2f %s to %s", transfer.Amount, transfer.Currency, transfer.ToAddress)

	// æ¨¡æ‹Ÿå­˜æ¬¾æ“ä½œ
	time.Sleep(time.Millisecond * 200)

	transfer.TransactionHash = fmt.Sprintf("deposit_%d", time.Now().UnixNano())
	transfer.Status = "COMPLETED"
	now := time.Now()
	transfer.CompletedAt = &now

	return nil
}

// executeWithdraw æ‰§è¡Œææ¬¾æ“ä½œ
func (rs *RiskScheduler) executeWithdraw(ctx context.Context, transfer *FundTransfer) error {
	log.Printf("Executing withdraw: %.2f %s from %s", transfer.Amount, transfer.Currency, transfer.FromAddress)

	// æ¨¡æ‹Ÿææ¬¾æ“ä½œ
	time.Sleep(time.Millisecond * 300)

	transfer.TransactionHash = fmt.Sprintf("withdraw_%d", time.Now().UnixNano())
	transfer.Status = "CONFIRMING"
	transfer.Confirmations = 0

	// æ¨¡æ‹Ÿç¡®è®¤è¿‡ç¨‹
	go rs.simulateConfirmationProcess(transfer)

	return nil
}

// simulateConfirmationProcess æ¨¡æ‹Ÿç¡®è®¤è¿‡ç¨‹
func (rs *RiskScheduler) simulateConfirmationProcess(transfer *FundTransfer) {
	for transfer.Confirmations < transfer.RequiredConfirms {
		time.Sleep(time.Second * 10) // æ¯10ç§’å¢åŠ ä¸€ä¸ªç¡®è®¤
		transfer.Confirmations++
		log.Printf("Transfer %s: %d/%d confirmations", transfer.ID, transfer.Confirmations, transfer.RequiredConfirms)
	}

	transfer.Status = "COMPLETED"
	now := time.Now()
	transfer.CompletedAt = &now
	log.Printf("Transfer %s completed", transfer.ID)
}

// recordTransferResult è®°å½•è½¬ç§»ç»“æœ
func (rs *RiskScheduler) recordTransferResult(ctx context.Context, result *TransferResult) error {
	query := `
		INSERT INTO fund_transfer_results (
			transfer_id, success, error_message, actual_amount,
			execution_time, created_at
		) VALUES ($1, $2, $3, $4, $5, NOW())
	`

	_, err := rs.db.ExecContext(ctx, query,
		result.Transfer.ID, result.Success, result.Error,
		result.ActualAmount, result.ExecutionTime.Milliseconds(),
	)

	return err
}

// integrateColdWalletOperations é›†æˆå†·é’±åŒ…æ“ä½œ
func (rs *RiskScheduler) integrateColdWalletOperations(ctx context.Context, transferResults []*TransferResult) error {
	var coldWalletOps []*ColdWalletOperation

	// ä¸ºæ¶‰åŠå†·é’±åŒ…çš„è½¬ç§»åˆ›å»ºå†·é’±åŒ…æ“ä½œ
	for _, result := range transferResults {
		if !result.Success {
			continue
		}

		transfer := result.Transfer
		if transfer.FromAddress == "cold_wallet" || transfer.ToAddress == "cold_wallet" {
			op := &ColdWalletOperation{
				ID:            fmt.Sprintf("cold_op_%d", time.Now().UnixNano()),
				Amount:        transfer.Amount,
				Currency:      transfer.Currency,
				Status:        "PENDING",
				SecurityLevel: "HIGH",
				RequiredSigs:  3, // éœ€è¦3ä¸ªç­¾å
				ProvidedSigs:  0,
				CreatedAt:     time.Now(),
				Metadata:      make(map[string]interface{}),
			}

			if transfer.ToAddress == "cold_wallet" {
				op.Type = "DEPOSIT"
				op.WalletAddress = transfer.ToAddress
			} else {
				op.Type = "WITHDRAW"
				op.WalletAddress = transfer.FromAddress
			}

			op.Metadata["transfer_id"] = transfer.ID
			op.Metadata["transfer_type"] = transfer.Type

			coldWalletOps = append(coldWalletOps, op)
		}
	}

	// æ‰§è¡Œå†·é’±åŒ…æ“ä½œ
	for _, op := range coldWalletOps {
		err := rs.executeColdWalletOperation(ctx, op)
		if err != nil {
			log.Printf("Failed to execute cold wallet operation %s: %v", op.ID, err)
			continue
		}
	}

	log.Printf("Integrated %d cold wallet operations", len(coldWalletOps))
	return nil
}

// executeColdWalletOperation æ‰§è¡Œå†·é’±åŒ…æ“ä½œ
func (rs *RiskScheduler) executeColdWalletOperation(ctx context.Context, op *ColdWalletOperation) error {
	log.Printf("Executing cold wallet operation: %s %s %.2f %s", op.Type, op.WalletAddress, op.Amount, op.Currency)

	// æ¨¡æ‹Ÿå¤šé‡ç­¾åè¿‡ç¨‹
	for op.ProvidedSigs < op.RequiredSigs {
		time.Sleep(time.Second * 5) // æ¨¡æ‹Ÿç­¾åå»¶è¿Ÿ
		op.ProvidedSigs++
		log.Printf("Cold wallet operation %s: %d/%d signatures", op.ID, op.ProvidedSigs, op.RequiredSigs)
	}

	op.Status = "COMPLETED"
	now := time.Now()
	op.ExecutedAt = &now

	// è®°å½•åˆ°æ•°æ®åº“
	err := rs.recordColdWalletOperation(ctx, op)
	if err != nil {
		return fmt.Errorf("failed to record cold wallet operation: %w", err)
	}

	return nil
}

// recordColdWalletOperation è®°å½•å†·é’±åŒ…æ“ä½œ
func (rs *RiskScheduler) recordColdWalletOperation(ctx context.Context, op *ColdWalletOperation) error {
	query := `
		INSERT INTO cold_wallet_operations (
			id, type, wallet_address, amount, currency, status,
			security_level, required_sigs, provided_sigs, created_at, executed_at
		) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)
	`

	_, err := rs.db.ExecContext(ctx, query,
		op.ID, op.Type, op.WalletAddress, op.Amount, op.Currency,
		op.Status, op.SecurityLevel, op.RequiredSigs, op.ProvidedSigs,
		op.CreatedAt, op.ExecutedAt,
	)

	return err
}

// updateFundProtectionProtocol æ›´æ–°èµ„é‡‘ä¿æŠ¤åè®®
func (rs *RiskScheduler) updateFundProtectionProtocol(ctx context.Context, distribution *OptimalFundDistribution, transferResults []*TransferResult) error {
	log.Printf("Updating fund protection protocol")

	// 1. è®¡ç®—æ–°çš„é£é™©å‚æ•°
	newRiskParams := rs.calculateNewRiskParameters(distribution, transferResults)

	// 2. æ›´æ–°ä¿æŠ¤é˜ˆå€¼
	err := rs.updateProtectionThresholds(ctx, newRiskParams)
	if err != nil {
		return fmt.Errorf("failed to update protection thresholds: %w", err)
	}

	// 3. æ›´æ–°ç›‘æ§è§„åˆ™
	err = rs.updateMonitoringRules(ctx, distribution)
	if err != nil {
		return fmt.Errorf("failed to update monitoring rules: %w", err)
	}

	// 4. è®°å½•åè®®æ›´æ–°å†å²
	err = rs.recordProtocolUpdate(ctx, distribution, transferResults, newRiskParams)
	if err != nil {
		log.Printf("Failed to record protocol update: %v", err)
		// ä¸è¿”å›é”™è¯¯ï¼Œå› ä¸ºè®°å½•å¤±è´¥ä¸åº”è¯¥å½±å“ä¸»æµç¨‹
	}

	log.Printf("Fund protection protocol updated successfully")
	return nil
}

// calculateNewRiskParameters è®¡ç®—æ–°çš„é£é™©å‚æ•°
func (rs *RiskScheduler) calculateNewRiskParameters(distribution *OptimalFundDistribution, transferResults []*TransferResult) map[string]float64 {
	params := make(map[string]float64)

	// åŸºäºç›®æ ‡åˆ†é…è®¡ç®—æ–°çš„é£é™©é˜ˆå€¼
	maxSingleAllocation := 0.0
	for _, ratio := range distribution.TargetDistribution {
		if ratio > maxSingleAllocation {
			maxSingleAllocation = ratio
		}
	}

	// åŸºäºè½¬ç§»æˆåŠŸç‡è°ƒæ•´å‚æ•°
	successRate := rs.calculateTransferSuccessRate(transferResults)
	riskAdjustment := 1.0
	if successRate < 0.8 {
		riskAdjustment = 1.2 // å¢åŠ é£é™©æ§åˆ¶
	} else if successRate > 0.95 {
		riskAdjustment = 0.9 // é€‚åº¦æ”¾æ¾
	}

	// è®¾ç½®æ–°çš„é£é™©å‚æ•°ï¼ŒåŒ¹é…risk_thresholdsè¡¨ç»“æ„
	params["max_margin_ratio"] = 0.8 * riskAdjustment
	params["warning_margin_ratio"] = 0.7 * riskAdjustment
	params["max_daily_loss"] = 5000.0 * riskAdjustment
	params["max_total_loss"] = 10000.0 * riskAdjustment
	params["max_drawdown_percent"] = 0.2 * riskAdjustment
	params["max_position_loss"] = 1000.0 * riskAdjustment
	params["max_position_loss_percent"] = 0.1 * riskAdjustment
	params["min_account_balance"] = 10000.0 / riskAdjustment
	params["max_leverage"] = 10.0 / riskAdjustment

	return params
}

// calculateTransferSuccessRate è®¡ç®—è½¬ç§»æˆåŠŸç‡
func (rs *RiskScheduler) calculateTransferSuccessRate(transferResults []*TransferResult) float64 {
	if len(transferResults) == 0 {
		return 1.0
	}

	successCount := 0
	for _, result := range transferResults {
		if result.Success {
			successCount++
		}
	}

	return float64(successCount) / float64(len(transferResults))
}

// updateProtectionThresholds æ›´æ–°ä¿æŠ¤é˜ˆå€¼
func (rs *RiskScheduler) updateProtectionThresholds(ctx context.Context, riskParams map[string]float64) error {
	// ä½¿ç”¨ç°æœ‰çš„risk_thresholdsè¡¨è€Œä¸æ˜¯ä¸å­˜åœ¨çš„fund_protection_thresholdsè¡¨
	query := `
		INSERT INTO risk_thresholds (
			name, max_margin_ratio, warning_margin_ratio, max_daily_loss,
			max_total_loss, max_drawdown_percent, max_position_loss,
			max_position_loss_percent, min_account_balance, max_leverage
		) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
		ON CONFLICT (name) DO UPDATE SET
			max_margin_ratio = EXCLUDED.max_margin_ratio,
			warning_margin_ratio = EXCLUDED.warning_margin_ratio,
			max_daily_loss = EXCLUDED.max_daily_loss,
			max_total_loss = EXCLUDED.max_total_loss,
			max_drawdown_percent = EXCLUDED.max_drawdown_percent,
			max_position_loss = EXCLUDED.max_position_loss,
			max_position_loss_percent = EXCLUDED.max_position_loss_percent,
			min_account_balance = EXCLUDED.min_account_balance,
			max_leverage = EXCLUDED.max_leverage
	`

	_, err := rs.db.ExecContext(ctx, query,
		"fund_protection",                       // name
		riskParams["max_margin_ratio"],          // max_margin_ratio
		riskParams["warning_margin_ratio"],      // warning_margin_ratio
		riskParams["max_daily_loss"],            // max_daily_loss
		riskParams["max_total_loss"],            // max_total_loss
		riskParams["max_drawdown_percent"],      // max_drawdown_percent
		riskParams["max_position_loss"],         // max_position_loss
		riskParams["max_position_loss_percent"], // max_position_loss_percent
		riskParams["min_account_balance"],       // min_account_balance
		int(riskParams["max_leverage"]),         // max_leverage
	)

	return err
}

// updateMonitoringRules æ›´æ–°ç›‘æ§è§„åˆ™
func (rs *RiskScheduler) updateMonitoringRules(ctx context.Context, distribution *OptimalFundDistribution) error {
	// ä¸ºæ¯ä¸ªåˆ†é…ä½ç½®åˆ›å»ºç›‘æ§è§„åˆ™
	for location, targetRatio := range distribution.TargetDistribution {
		rule := map[string]interface{}{
			"location":           location,
			"target_ratio":       targetRatio,
			"warning_threshold":  targetRatio * 1.1, // è¶…å‡ºç›®æ ‡10%æ—¶å‘Šè­¦
			"critical_threshold": targetRatio * 1.3, // è¶…å‡ºç›®æ ‡30%æ—¶ç´§æ€¥å‘Šè­¦
			"check_interval":     300,               // 5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
		}

		err := rs.createOrUpdateMonitoringRule(ctx, rule)
		if err != nil {
			log.Printf("Failed to update monitoring rule for %s: %v", location, err)
			continue
		}
	}

	return nil
}

// createOrUpdateMonitoringRule åˆ›å»ºæˆ–æ›´æ–°ç›‘æ§è§„åˆ™
func (rs *RiskScheduler) createOrUpdateMonitoringRule(ctx context.Context, rule map[string]interface{}) error {
	query := `
		INSERT INTO fund_monitoring_rules (
			location, target_ratio, warning_threshold, critical_threshold,
			check_interval, created_at, updated_at
		) VALUES ($1, $2, $3, $4, $5, NOW(), NOW())
		ON CONFLICT (location) DO UPDATE SET
			target_ratio = EXCLUDED.target_ratio,
			warning_threshold = EXCLUDED.warning_threshold,
			critical_threshold = EXCLUDED.critical_threshold,
			check_interval = EXCLUDED.check_interval,
			updated_at = NOW()
	`

	_, err := rs.db.ExecContext(ctx, query,
		rule["location"],
		rule["target_ratio"],
		rule["warning_threshold"],
		rule["critical_threshold"],
		rule["check_interval"],
	)

	return err
}

// recordProtocolUpdate è®°å½•åè®®æ›´æ–°å†å²
func (rs *RiskScheduler) recordProtocolUpdate(ctx context.Context, distribution *OptimalFundDistribution, transferResults []*TransferResult, riskParams map[string]float64) error {
	// åºåˆ—åŒ–åˆ†é…ä¿¡æ¯
	distributionJSON := ""
	for location, ratio := range distribution.TargetDistribution {
		if distributionJSON != "" {
			distributionJSON += ","
		}
		distributionJSON += fmt.Sprintf(`"%s":%.4f`, location, ratio)
	}
	distributionJSON = "{" + distributionJSON + "}"

	// åºåˆ—åŒ–é£é™©å‚æ•°
	paramsJSON := ""
	for param, value := range riskParams {
		if paramsJSON != "" {
			paramsJSON += ","
		}
		paramsJSON += fmt.Sprintf(`"%s":%.4f`, param, value)
	}
	paramsJSON = "{" + paramsJSON + "}"

	query := `
		INSERT INTO fund_protection_history (
			target_distribution, risk_parameters, transfer_count,
			success_rate, expected_risk_reduction, created_at
		) VALUES ($1, $2, $3, $4, $5, NOW())
	`

	successRate := rs.calculateTransferSuccessRate(transferResults)

	_, err := rs.db.ExecContext(ctx, query,
		distributionJSON, paramsJSON, len(transferResults),
		successRate, distribution.ExpectedRiskReduction,
	)

	return err
}

// å¤šç­–ç•¥å¯¹å†²ç›¸å…³æ•°æ®ç»“æ„

// StrategyCorrelationMatrix ç­–ç•¥ç›¸å…³æ€§çŸ©é˜µ
type StrategyCorrelationMatrix struct {
	Strategies   []string                      `json:"strategies"`
	Matrix       map[string]map[string]float64 `json:"matrix"`
	Timestamp    time.Time                     `json:"timestamp"`
	UpdatePeriod time.Duration                 `json:"update_period"`
	Confidence   float64                       `json:"confidence"`
	SampleSize   int                           `json:"sample_size"`
}

// DynamicHedgeRatio åŠ¨æ€å¯¹å†²æ¯”ç‡
type DynamicHedgeRatio struct {
	BaseStrategy  string                 `json:"base_strategy"`
	HedgeStrategy string                 `json:"hedge_strategy"`
	Ratio         float64                `json:"ratio"`
	Confidence    float64                `json:"confidence"`
	RiskReduction float64                `json:"risk_reduction"`
	Cost          float64                `json:"cost"`
	Effectiveness float64                `json:"effectiveness"`
	LastUpdate    time.Time              `json:"last_update"`
	NextUpdate    time.Time              `json:"next_update"`
	Metadata      map[string]interface{} `json:"metadata"`
}

// HedgeOperation å¯¹å†²æ“ä½œ
type HedgeOperation struct {
	ID            string                 `json:"id"`
	Type          string                 `json:"type"` // OPEN, CLOSE, ADJUST
	BaseStrategy  string                 `json:"base_strategy"`
	HedgeStrategy string                 `json:"hedge_strategy"`
	BasePosition  float64                `json:"base_position"`
	HedgePosition float64                `json:"hedge_position"`
	TargetRatio   float64                `json:"target_ratio"`
	ActualRatio   float64                `json:"actual_ratio"`
	Status        string                 `json:"status"`
	ExecutedAt    *time.Time             `json:"executed_at"`
	CompletedAt   *time.Time             `json:"completed_at"`
	Cost          float64                `json:"cost"`
	Slippage      float64                `json:"slippage"`
	Metadata      map[string]interface{} `json:"metadata"`
}

// HedgeResult å¯¹å†²ç»“æœ
type HedgeResult struct {
	Operation          *HedgeOperation        `json:"operation"`
	Success            bool                   `json:"success"`
	Error              string                 `json:"error,omitempty"`
	ExecutionTime      time.Duration          `json:"execution_time"`
	ActualCost         float64                `json:"actual_cost"`
	RiskReduction      float64                `json:"risk_reduction"`
	EffectivenessScore float64                `json:"effectiveness_score"`
	Metadata           map[string]interface{} `json:"metadata"`
}

// HedgeEffectivenessMetrics å¯¹å†²æ•ˆæœæŒ‡æ ‡
type HedgeEffectivenessMetrics struct {
	HedgeID              string    `json:"hedge_id"`
	CorrelationStability float64   `json:"correlation_stability"`
	RiskReductionActual  float64   `json:"risk_reduction_actual"`
	RiskReductionTarget  float64   `json:"risk_reduction_target"`
	CostEfficiency       float64   `json:"cost_efficiency"`
	Sharpe               float64   `json:"sharpe"`
	MaxDrawdown          float64   `json:"max_drawdown"`
	OverallScore         float64   `json:"overall_score"`
	Timestamp            time.Time `json:"timestamp"`
}

// å¤šç­–ç•¥å¯¹å†²æ–¹æ³•å®ç°

// analyzeStrategyCorrelations åˆ†æç­–ç•¥é—´ç›¸å…³æ€§
func (ps *PositionScheduler) analyzeStrategyCorrelations(ctx context.Context) (*StrategyCorrelationMatrix, error) {
	// 1. è·å–æ´»è·ƒç­–ç•¥åˆ—è¡¨
	strategies, err := ps.getActiveStrategiesForHedging(ctx)
	if err != nil {
		return nil, fmt.Errorf("failed to get active strategies: %w", err)
	}

	// 2. è·å–ç­–ç•¥æ”¶ç›Šæ•°æ®
	strategyReturns, err := ps.getStrategyReturns(ctx, strategies, 30) // 30å¤©æ•°æ®
	if err != nil {
		return nil, fmt.Errorf("failed to get strategy returns: %w", err)
	}

	// 3. è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
	matrix := make(map[string]map[string]float64)
	for _, strategy1 := range strategies {
		matrix[strategy1] = make(map[string]float64)
		for _, strategy2 := range strategies {
			if strategy1 == strategy2 {
				matrix[strategy1][strategy2] = 1.0
			} else {
				correlation := ps.calculateCorrelation(strategyReturns[strategy1], strategyReturns[strategy2])
				matrix[strategy1][strategy2] = correlation
			}
		}
	}

	// 4. è®¡ç®—ç½®ä¿¡åº¦
	confidence := ps.calculateCorrelationConfidence(strategyReturns)

	correlationMatrix := &StrategyCorrelationMatrix{
		Strategies:   strategies,
		Matrix:       matrix,
		Timestamp:    time.Now(),
		UpdatePeriod: time.Hour * 4, // 4å°æ—¶æ›´æ–°ä¸€æ¬¡
		Confidence:   confidence,
		SampleSize:   len(strategyReturns[strategies[0]]), // å‡è®¾æ‰€æœ‰ç­–ç•¥æ•°æ®é•¿åº¦ç›¸åŒ
	}

	log.Printf("Strategy correlation analysis completed for %d strategies", len(strategies))
	return correlationMatrix, nil
}

// getActiveStrategiesForHedging è·å–ç”¨äºå¯¹å†²çš„æ´»è·ƒç­–ç•¥
func (ps *PositionScheduler) getActiveStrategiesForHedging(ctx context.Context) ([]string, error) {
	query := `
		SELECT strategy_id
		FROM strategy_positions
		WHERE status = 'ACTIVE'
		AND position_size > 0
		AND updated_at > NOW() - INTERVAL '1 hour'
		GROUP BY strategy_id
		HAVING COUNT(*) > 0
		ORDER BY SUM(position_size) DESC
		LIMIT 10
	`

	rows, err := ps.db.QueryContext(ctx, query)
	if err != nil {
		return nil, fmt.Errorf("failed to query active strategies: %w", err)
	}
	defer rows.Close()

	var strategies []string
	for rows.Next() {
		var strategyID string
		if err := rows.Scan(&strategyID); err != nil {
			return nil, fmt.Errorf("failed to scan strategy ID: %w", err)
		}
		strategies = append(strategies, strategyID)
	}

	// å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥
	if len(strategies) == 0 {
		strategies = []string{
			"momentum_strategy",
			"mean_reversion_strategy",
			"arbitrage_strategy",
			"trend_following_strategy",
		}
	}

	return strategies, nil
}

// getStrategyReturns è·å–ç­–ç•¥æ”¶ç›Šæ•°æ®
func (ps *PositionScheduler) getStrategyReturns(ctx context.Context, strategies []string, days int) (map[string][]float64, error) {
	strategyReturns := make(map[string][]float64)

	for _, strategy := range strategies {
		query := `
			SELECT daily_return
			FROM strategy_performance
			WHERE strategy_id = $1
			AND date >= NOW() - INTERVAL '%d days'
			ORDER BY date ASC
		`

		rows, err := ps.db.QueryContext(ctx, fmt.Sprintf(query, days), strategy)
		if err != nil {
			log.Printf("Failed to query returns for strategy %s: %v", strategy, err)
			// ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
			strategyReturns[strategy] = ps.generateMockReturns(days)
			continue
		}

		var returns []float64
		for rows.Next() {
			var dailyReturn float64
			if err := rows.Scan(&dailyReturn); err != nil {
				rows.Close()
				return nil, fmt.Errorf("failed to scan daily return: %w", err)
			}
			returns = append(returns, dailyReturn)
		}
		rows.Close()

		if len(returns) == 0 {
			// ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
			returns = ps.generateMockReturns(days)
		}

		strategyReturns[strategy] = returns
	}

	return strategyReturns, nil
}

// generateMockReturns ç”Ÿæˆæ¨¡æ‹Ÿæ”¶ç›Šæ•°æ®
func (ps *PositionScheduler) generateMockReturns(days int) []float64 {
	returns := make([]float64, days)
	for i := 0; i < days; i++ {
		// ç”Ÿæˆæ­£æ€åˆ†å¸ƒçš„éšæœºæ”¶ç›Š
		returns[i] = (float64(i%10) - 5.0) / 100.0 // -5% åˆ° +4% çš„æ”¶ç›Š
	}
	return returns
}

// calculateCorrelation è®¡ç®—ä¸¤ä¸ªåºåˆ—çš„ç›¸å…³ç³»æ•°
func (ps *PositionScheduler) calculateCorrelation(x, y []float64) float64 {
	if len(x) != len(y) || len(x) == 0 {
		return 0.0
	}

	n := float64(len(x))

	// è®¡ç®—å‡å€¼
	meanX, meanY := 0.0, 0.0
	for i := 0; i < len(x); i++ {
		meanX += x[i]
		meanY += y[i]
	}
	meanX /= n
	meanY /= n

	// è®¡ç®—åæ–¹å·®å’Œæ–¹å·®
	covariance, varianceX, varianceY := 0.0, 0.0, 0.0
	for i := 0; i < len(x); i++ {
		dx := x[i] - meanX
		dy := y[i] - meanY
		covariance += dx * dy
		varianceX += dx * dx
		varianceY += dy * dy
	}

	// è®¡ç®—ç›¸å…³ç³»æ•°
	if varianceX == 0 || varianceY == 0 {
		return 0.0
	}

	correlation := covariance / math.Sqrt(varianceX*varianceY)
	return correlation
}

// calculateCorrelationConfidence è®¡ç®—ç›¸å…³æ€§ç½®ä¿¡åº¦
func (ps *PositionScheduler) calculateCorrelationConfidence(strategyReturns map[string][]float64) float64 {
	// åŸºäºæ ·æœ¬å¤§å°å’Œæ•°æ®è´¨é‡è®¡ç®—ç½®ä¿¡åº¦
	minSampleSize := math.MaxInt32
	for _, returns := range strategyReturns {
		if len(returns) < minSampleSize {
			minSampleSize = len(returns)
		}
	}

	// æ ·æœ¬å¤§å°è¶Šå¤§ï¼Œç½®ä¿¡åº¦è¶Šé«˜
	confidence := math.Min(1.0, float64(minSampleSize)/30.0) // 30å¤©æ•°æ®ä¸ºæ»¡åˆ†

	// è€ƒè™‘æ•°æ®å®Œæ•´æ€§
	if minSampleSize < 7 {
		confidence *= 0.5 // å°‘äºä¸€å‘¨æ•°æ®ï¼Œç½®ä¿¡åº¦å‡åŠ
	}

	return confidence
}

// calculateDynamicHedgeRatios è®¡ç®—åŠ¨æ€å¯¹å†²æ¯”ç‡
func (ps *PositionScheduler) calculateDynamicHedgeRatios(ctx context.Context, correlationMatrix *StrategyCorrelationMatrix) ([]*DynamicHedgeRatio, error) {
	var hedgeRatios []*DynamicHedgeRatio

	// è·å–å½“å‰ç­–ç•¥ä»“ä½
	strategyPositions, err := ps.getStrategyPositions(ctx, correlationMatrix.Strategies)
	if err != nil {
		return nil, fmt.Errorf("failed to get strategy positions: %w", err)
	}

	// ä¸ºæ¯å¯¹ç­–ç•¥è®¡ç®—å¯¹å†²æ¯”ç‡
	for i, baseStrategy := range correlationMatrix.Strategies {
		for j, hedgeStrategy := range correlationMatrix.Strategies {
			if i >= j { // é¿å…é‡å¤è®¡ç®—
				continue
			}

			correlation := correlationMatrix.Matrix[baseStrategy][hedgeStrategy]

			// åªå¯¹ç›¸å…³æ€§è¾ƒé«˜çš„ç­–ç•¥è¿›è¡Œå¯¹å†²
			if math.Abs(correlation) < 0.3 {
				continue
			}

			// è®¡ç®—æœ€ä¼˜å¯¹å†²æ¯”ç‡
			optimalRatio := ps.calculateOptimalHedgeRatio(
				strategyPositions[baseStrategy],
				strategyPositions[hedgeStrategy],
				correlation,
			)

			// è®¡ç®—é£é™©é™ä½å’Œæˆæœ¬
			riskReduction := ps.calculateRiskReduction(correlation, optimalRatio)
			cost := ps.calculateHedgeCost(strategyPositions[baseStrategy], strategyPositions[hedgeStrategy], optimalRatio)

			// è®¡ç®—æ•ˆæœè¯„åˆ†
			effectiveness := ps.calculateHedgeEffectiveness(riskReduction, cost, correlation)

			hedgeRatio := &DynamicHedgeRatio{
				BaseStrategy:  baseStrategy,
				HedgeStrategy: hedgeStrategy,
				Ratio:         optimalRatio,
				Confidence:    correlationMatrix.Confidence,
				RiskReduction: riskReduction,
				Cost:          cost,
				Effectiveness: effectiveness,
				LastUpdate:    time.Now(),
				NextUpdate:    time.Now().Add(time.Hour * 2), // 2å°æ—¶åæ›´æ–°
				Metadata:      make(map[string]interface{}),
			}

			hedgeRatio.Metadata["correlation"] = correlation
			hedgeRatio.Metadata["base_position"] = strategyPositions[baseStrategy]
			hedgeRatio.Metadata["hedge_position"] = strategyPositions[hedgeStrategy]

			hedgeRatios = append(hedgeRatios, hedgeRatio)
		}
	}

	// æŒ‰æ•ˆæœè¯„åˆ†æ’åº
	sort.Slice(hedgeRatios, func(i, j int) bool {
		return hedgeRatios[i].Effectiveness > hedgeRatios[j].Effectiveness
	})

	log.Printf("Calculated %d dynamic hedge ratios", len(hedgeRatios))
	return hedgeRatios, nil
}

// getStrategyPositions è·å–ç­–ç•¥ä»“ä½
func (ps *PositionScheduler) getStrategyPositions(ctx context.Context, strategies []string) (map[string]float64, error) {
	positions := make(map[string]float64)

	for _, strategy := range strategies {
		query := `
			SELECT COALESCE(SUM(position_size), 0) as total_position
			FROM strategy_positions
			WHERE strategy_id = $1
			AND status = 'ACTIVE'
		`

		var totalPosition float64
		err := ps.db.QueryRowContext(ctx, query, strategy).Scan(&totalPosition)
		if err != nil {
			log.Printf("Failed to get position for strategy %s: %v", strategy, err)
			// ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
			totalPosition = 10000.0 + float64(len(strategy)*1000)
		}

		positions[strategy] = totalPosition
	}

	return positions, nil
}

// calculateOptimalHedgeRatio è®¡ç®—æœ€ä¼˜å¯¹å†²æ¯”ç‡
func (ps *PositionScheduler) calculateOptimalHedgeRatio(basePosition, hedgePosition, correlation float64) float64 {
	// åŸºäºæœ€å°æ–¹å·®å¯¹å†²æ¯”ç‡å…¬å¼
	// h* = Cov(S1, S2) / Var(S2)
	// ç®€åŒ–è®¡ç®—ï¼šä½¿ç”¨ç›¸å…³ç³»æ•°å’Œä»“ä½å¤§å°

	if hedgePosition == 0 {
		return 0.0
	}

	// åŸºç¡€å¯¹å†²æ¯”ç‡
	baseRatio := correlation * (basePosition / hedgePosition)

	// è€ƒè™‘é£é™©è°ƒæ•´
	riskAdjustment := 1.0
	if math.Abs(correlation) > 0.8 {
		riskAdjustment = 1.2 // é«˜ç›¸å…³æ€§æ—¶å¢åŠ å¯¹å†²æ¯”ç‡
	} else if math.Abs(correlation) < 0.5 {
		riskAdjustment = 0.8 // ä½ç›¸å…³æ€§æ—¶å‡å°‘å¯¹å†²æ¯”ç‡
	}

	optimalRatio := baseRatio * riskAdjustment

	// é™åˆ¶å¯¹å†²æ¯”ç‡åœ¨åˆç†èŒƒå›´å†…
	return math.Max(-2.0, math.Min(2.0, optimalRatio))
}

// calculateRiskReduction è®¡ç®—é£é™©é™ä½
func (ps *PositionScheduler) calculateRiskReduction(correlation, hedgeRatio float64) float64 {
	// åŸºäºæŠ•èµ„ç»„åˆç†è®ºè®¡ç®—é£é™©é™ä½
	// ÏƒÂ²(portfolio) = ÏƒÂ²(base) + hÂ²ÏƒÂ²(hedge) + 2h*Ï*Ïƒ(base)*Ïƒ(hedge)
	// ç®€åŒ–è®¡ç®—

	correlationEffect := math.Abs(correlation) * math.Abs(hedgeRatio)
	diversificationBenefit := correlationEffect * 0.5 // åˆ†æ•£åŒ–æ”¶ç›Š

	// é£é™©é™ä½ç™¾åˆ†æ¯”
	riskReduction := math.Min(0.8, diversificationBenefit) // æœ€å¤§80%é£é™©é™ä½

	return riskReduction
}

// calculateHedgeCost è®¡ç®—å¯¹å†²æˆæœ¬
func (ps *PositionScheduler) calculateHedgeCost(basePosition, hedgePosition, hedgeRatio float64) float64 {
	// è®¡ç®—æ‰§è¡Œå¯¹å†²çš„æˆæœ¬
	hedgeAmount := math.Abs(hedgeRatio * basePosition)

	// äº¤æ˜“æˆæœ¬ (å‡è®¾0.1%æ‰‹ç»­è´¹)
	transactionCost := hedgeAmount * 0.001

	// èµ„é‡‘å ç”¨æˆæœ¬ (å‡è®¾å¹´åŒ–5%ï¼ŒæŒ‰æ—¥è®¡ç®—)
	fundingCost := hedgeAmount * 0.05 / 365

	// æ»‘ç‚¹æˆæœ¬ (å‡è®¾0.05%)
	slippageCost := hedgeAmount * 0.0005

	totalCost := transactionCost + fundingCost + slippageCost

	return totalCost
}

// calculateHedgeEffectiveness è®¡ç®—å¯¹å†²æ•ˆæœ
func (ps *PositionScheduler) calculateHedgeEffectiveness(riskReduction, cost, correlation float64) float64 {
	// æ•ˆæœè¯„åˆ† = é£é™©é™ä½æ”¶ç›Š / æˆæœ¬
	if cost == 0 {
		return riskReduction
	}

	// åŸºç¡€æ•ˆæœè¯„åˆ†
	baseScore := riskReduction / (cost + 0.001) // é¿å…é™¤é›¶

	// ç›¸å…³æ€§è°ƒæ•´
	correlationBonus := math.Abs(correlation) * 0.5

	// ç»¼åˆè¯„åˆ†
	effectiveness := (baseScore + correlationBonus) / 2.0

	return math.Min(1.0, effectiveness)
}

// executeAutoHedgeOperations æ‰§è¡Œè‡ªåŠ¨å¯¹å†²æ“ä½œ
func (ps *PositionScheduler) executeAutoHedgeOperations(ctx context.Context, hedgeRatios []*DynamicHedgeRatio) ([]*HedgeResult, error) {
	var results []*HedgeResult

	log.Printf("Executing %d auto hedge operations", len(hedgeRatios))

	for _, ratio := range hedgeRatios {
		// åªæ‰§è¡Œæ•ˆæœè¯„åˆ†è¾ƒé«˜çš„å¯¹å†²
		if ratio.Effectiveness < 0.3 {
			continue
		}

		// åˆ›å»ºå¯¹å†²æ“ä½œ
		operation := &HedgeOperation{
			ID:            fmt.Sprintf("hedge_%d", time.Now().UnixNano()),
			Type:          "OPEN",
			BaseStrategy:  ratio.BaseStrategy,
			HedgeStrategy: ratio.HedgeStrategy,
			BasePosition:  ratio.Metadata["base_position"].(float64),
			HedgePosition: ratio.Metadata["hedge_position"].(float64),
			TargetRatio:   ratio.Ratio,
			Status:        "PENDING",
			Cost:          ratio.Cost,
			Metadata:      make(map[string]interface{}),
		}

		operation.Metadata["correlation"] = ratio.Metadata["correlation"]
		operation.Metadata["risk_reduction"] = ratio.RiskReduction
		operation.Metadata["effectiveness"] = ratio.Effectiveness

		// æ‰§è¡Œå¯¹å†²æ“ä½œ
		result := ps.executeHedgeOperation(ctx, operation)
		results = append(results, result)

		// è®°å½•æ“ä½œç»“æœ
		err := ps.recordHedgeOperation(ctx, operation, result)
		if err != nil {
			log.Printf("Failed to record hedge operation: %v", err)
		}

		// æ·»åŠ å»¶è¿Ÿé¿å…è¿‡äºé¢‘ç¹çš„æ“ä½œ
		time.Sleep(time.Millisecond * 500)
	}

	successCount := 0
	for _, result := range results {
		if result.Success {
			successCount++
		}
	}

	log.Printf("Auto hedge operations completed: %d/%d successful", successCount, len(results))
	return results, nil
}

// executeHedgeOperation æ‰§è¡Œå•ä¸ªå¯¹å†²æ“ä½œ
func (ps *PositionScheduler) executeHedgeOperation(ctx context.Context, operation *HedgeOperation) *HedgeResult {
	startTime := time.Now()

	result := &HedgeResult{
		Operation: operation,
		Success:   false,
		Metadata:  make(map[string]interface{}),
	}

	// æ›´æ–°æ“ä½œçŠ¶æ€
	operation.Status = "EXECUTING"
	now := time.Now()
	operation.ExecutedAt = &now

	// è®¡ç®—å®é™…å¯¹å†²ä»“ä½
	hedgeAmount := operation.TargetRatio * operation.BasePosition

	// æ¨¡æ‹Ÿæ‰§è¡Œå¯¹å†²äº¤æ˜“
	err := ps.simulateHedgeExecution(ctx, operation, hedgeAmount)
	if err != nil {
		result.Error = err.Error()
		operation.Status = "FAILED"
		log.Printf("Hedge operation failed: %s <-> %s, error: %v",
			operation.BaseStrategy, operation.HedgeStrategy, err)
	} else {
		result.Success = true
		operation.Status = "COMPLETED"
		operation.ActualRatio = operation.TargetRatio // ç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥è®¡ç®—çœŸå®æ¯”ç‡
		completedAt := time.Now()
		operation.CompletedAt = &completedAt

		log.Printf("Hedge operation completed: %s <-> %s, ratio: %.4f",
			operation.BaseStrategy, operation.HedgeStrategy, operation.ActualRatio)
	}

	result.ExecutionTime = time.Since(startTime)
	result.ActualCost = operation.Cost
	result.RiskReduction = operation.Metadata["risk_reduction"].(float64)
	result.EffectivenessScore = operation.Metadata["effectiveness"].(float64)

	return result
}

// simulateHedgeExecution æ¨¡æ‹Ÿå¯¹å†²æ‰§è¡Œ
func (ps *PositionScheduler) simulateHedgeExecution(ctx context.Context, operation *HedgeOperation, hedgeAmount float64) error {
	// æ£€æŸ¥èµ„é‡‘å……è¶³æ€§
	if math.Abs(hedgeAmount) > operation.HedgePosition {
		return fmt.Errorf("insufficient hedge position: required %.2f, available %.2f",
			math.Abs(hedgeAmount), operation.HedgePosition)
	}

	// æ¨¡æ‹Ÿå¸‚åœºå†²å‡»å’Œæ»‘ç‚¹
	marketImpact := math.Abs(hedgeAmount) / 1000000.0 // ç®€åŒ–çš„å¸‚åœºå†²å‡»æ¨¡å‹
	if marketImpact > 0.01 {                          // 1%ä»¥ä¸Šçš„å¸‚åœºå†²å‡»è®¤ä¸ºè¿‡å¤§
		return fmt.Errorf("market impact too high: %.4f", marketImpact)
	}

	// æ¨¡æ‹Ÿæ‰§è¡Œå»¶è¿Ÿ
	time.Sleep(time.Millisecond * 200)

	// è®¡ç®—æ»‘ç‚¹
	slippage := marketImpact * 0.5
	operation.Slippage = slippage
	operation.Cost += math.Abs(hedgeAmount) * slippage

	return nil
}

// recordHedgeOperation è®°å½•å¯¹å†²æ“ä½œ
func (ps *PositionScheduler) recordHedgeOperation(ctx context.Context, operation *HedgeOperation, result *HedgeResult) error {
	query := `
		INSERT INTO hedge_operations (
			id, type, base_strategy, hedge_strategy, base_position,
			hedge_position, target_ratio, actual_ratio, status,
			cost, slippage, success, execution_time, created_at
		) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, NOW())
	`

	_, err := ps.db.ExecContext(ctx, query,
		operation.ID, operation.Type, operation.BaseStrategy, operation.HedgeStrategy,
		operation.BasePosition, operation.HedgePosition, operation.TargetRatio,
		operation.ActualRatio, operation.Status, operation.Cost, operation.Slippage,
		result.Success, result.ExecutionTime.Milliseconds(),
	)

	return err
}

// monitorHedgeEffectiveness ç›‘æ§å¯¹å†²æ•ˆæœ
func (ps *PositionScheduler) monitorHedgeEffectiveness(ctx context.Context, hedgeResults []*HedgeResult) error {
	log.Printf("Monitoring hedge effectiveness for %d operations", len(hedgeResults))

	for _, result := range hedgeResults {
		if !result.Success {
			continue
		}

		// è®¡ç®—å¯¹å†²æ•ˆæœæŒ‡æ ‡
		metrics := ps.calculateHedgeEffectivenessMetrics(ctx, result)

		// è®°å½•æ•ˆæœæŒ‡æ ‡
		err := ps.recordHedgeEffectivenessMetrics(ctx, metrics)
		if err != nil {
			log.Printf("Failed to record hedge effectiveness metrics for %s: %v",
				result.Operation.ID, err)
			continue
		}

		// æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒæ•´å¯¹å†²
		if metrics.OverallScore < 0.5 {
			log.Printf("Hedge effectiveness below threshold for %s: %.4f",
				result.Operation.ID, metrics.OverallScore)

			// å¯ä»¥åœ¨è¿™é‡Œè§¦å‘å¯¹å†²è°ƒæ•´é€»è¾‘
			ps.scheduleHedgeAdjustment(ctx, result.Operation)
		}
	}

	return nil
}

// calculateHedgeEffectivenessMetrics è®¡ç®—å¯¹å†²æ•ˆæœæŒ‡æ ‡
func (ps *PositionScheduler) calculateHedgeEffectivenessMetrics(ctx context.Context, result *HedgeResult) *HedgeEffectivenessMetrics {
	operation := result.Operation

	// è·å–å¯¹å†²åçš„ç›¸å…³æ€§ç¨³å®šæ€§
	correlationStability := ps.calculateCorrelationStability(ctx, operation)

	// è®¡ç®—å®é™…é£é™©é™ä½
	actualRiskReduction := ps.calculateActualRiskReduction(ctx, operation)

	// è®¡ç®—æˆæœ¬æ•ˆç‡
	costEfficiency := result.RiskReduction / (result.ActualCost + 0.001) // é¿å…é™¤é›¶

	// è®¡ç®—å¤æ™®æ¯”ç‡æ”¹å–„
	sharpeImprovement := ps.calculateSharpeImprovement(ctx, operation)

	// è®¡ç®—æœ€å¤§å›æ’¤æ”¹å–„
	maxDrawdownImprovement := ps.calculateMaxDrawdownImprovement(ctx, operation)

	// è®¡ç®—ç»¼åˆè¯„åˆ†
	overallScore := (correlationStability*0.2 +
		actualRiskReduction*0.3 +
		costEfficiency*0.2 +
		sharpeImprovement*0.15 +
		maxDrawdownImprovement*0.15)

	metrics := &HedgeEffectivenessMetrics{
		HedgeID:              operation.ID,
		CorrelationStability: correlationStability,
		RiskReductionActual:  actualRiskReduction,
		RiskReductionTarget:  result.RiskReduction,
		CostEfficiency:       costEfficiency,
		Sharpe:               sharpeImprovement,
		MaxDrawdown:          maxDrawdownImprovement,
		OverallScore:         overallScore,
		Timestamp:            time.Now(),
	}

	return metrics
}

// calculateCorrelationStability è®¡ç®—ç›¸å…³æ€§ç¨³å®šæ€§
func (ps *PositionScheduler) calculateCorrelationStability(ctx context.Context, operation *HedgeOperation) float64 {
	// ç®€åŒ–å®ç°ï¼šåŸºäºå†å²ç›¸å…³æ€§çš„ç¨³å®šæ€§
	historicalCorrelation := operation.Metadata["correlation"].(float64)

	// æ¨¡æ‹Ÿå½“å‰ç›¸å…³æ€§ï¼ˆå®é™…åº”è¯¥ä»å®æ—¶æ•°æ®è®¡ç®—ï¼‰
	currentCorrelation := historicalCorrelation + (float64(time.Now().Unix()%10)-5.0)/100.0

	// è®¡ç®—ç¨³å®šæ€§ï¼ˆç›¸å…³æ€§å˜åŒ–è¶Šå°ï¼Œç¨³å®šæ€§è¶Šé«˜ï¼‰
	stability := 1.0 - math.Abs(historicalCorrelation-currentCorrelation)
	return math.Max(0.0, stability)
}

// calculateActualRiskReduction è®¡ç®—å®é™…é£é™©é™ä½
func (ps *PositionScheduler) calculateActualRiskReduction(ctx context.Context, operation *HedgeOperation) float64 {
	// ç®€åŒ–å®ç°ï¼šåŸºäºå¯¹å†²æ¯”ç‡å’Œç›¸å…³æ€§è®¡ç®—å®é™…é£é™©é™ä½
	correlation := operation.Metadata["correlation"].(float64)
	actualRatio := operation.ActualRatio

	// å®é™…é£é™©é™ä½ = |ç›¸å…³æ€§| * |å¯¹å†²æ¯”ç‡| * æ•ˆç‡å› å­
	efficiencyFactor := 0.8 // å‡è®¾80%çš„ç†è®ºæ•ˆç‡
	actualRiskReduction := math.Abs(correlation) * math.Abs(actualRatio) * efficiencyFactor

	return math.Min(1.0, actualRiskReduction)
}

// calculateSharpeImprovement è®¡ç®—å¤æ™®æ¯”ç‡æ”¹å–„
func (ps *PositionScheduler) calculateSharpeImprovement(ctx context.Context, operation *HedgeOperation) float64 {
	// ç®€åŒ–å®ç°ï¼šåŸºäºé£é™©é™ä½ä¼°ç®—å¤æ™®æ¯”ç‡æ”¹å–„
	riskReduction := operation.Metadata["risk_reduction"].(float64)

	// å¤æ™®æ¯”ç‡æ”¹å–„é€šå¸¸ä¸é£é™©é™ä½æˆæ­£æ¯”
	sharpeImprovement := riskReduction * 0.5 // å‡è®¾50%çš„è½¬æ¢æ•ˆç‡

	return sharpeImprovement
}

// calculateMaxDrawdownImprovement è®¡ç®—æœ€å¤§å›æ’¤æ”¹å–„
func (ps *PositionScheduler) calculateMaxDrawdownImprovement(ctx context.Context, operation *HedgeOperation) float64 {
	// ç®€åŒ–å®ç°ï¼šåŸºäºå¯¹å†²æ•ˆæœä¼°ç®—å›æ’¤æ”¹å–„
	riskReduction := operation.Metadata["risk_reduction"].(float64)

	// å›æ’¤æ”¹å–„é€šå¸¸ä¸é£é™©é™ä½ç›¸å…³
	drawdownImprovement := riskReduction * 0.6 // å‡è®¾60%çš„è½¬æ¢æ•ˆç‡

	return drawdownImprovement
}

// recordHedgeEffectivenessMetrics è®°å½•å¯¹å†²æ•ˆæœæŒ‡æ ‡
func (ps *PositionScheduler) recordHedgeEffectivenessMetrics(ctx context.Context, metrics *HedgeEffectivenessMetrics) error {
	query := `
		INSERT INTO hedge_effectiveness_metrics (
			hedge_id, correlation_stability, risk_reduction_actual,
			risk_reduction_target, cost_efficiency, sharpe, max_drawdown,
			overall_score, created_at
		) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, NOW())
	`

	_, err := ps.db.ExecContext(ctx, query,
		metrics.HedgeID, metrics.CorrelationStability, metrics.RiskReductionActual,
		metrics.RiskReductionTarget, metrics.CostEfficiency, metrics.Sharpe,
		metrics.MaxDrawdown, metrics.OverallScore,
	)

	return err
}

// scheduleHedgeAdjustment å®‰æ’å¯¹å†²è°ƒæ•´
func (ps *PositionScheduler) scheduleHedgeAdjustment(ctx context.Context, operation *HedgeOperation) {
	log.Printf("Scheduling hedge adjustment for operation %s", operation.ID)

	// è¿™é‡Œå¯ä»¥å®ç°å¯¹å†²è°ƒæ•´çš„è°ƒåº¦é€»è¾‘
	// ä¾‹å¦‚ï¼šé‡æ–°è®¡ç®—å¯¹å†²æ¯”ç‡ã€è°ƒæ•´ä»“ä½ç­‰
	// ç›®å‰åªè®°å½•æ—¥å¿—
}

// updateHedgeHistory æ›´æ–°å¯¹å†²å†å²è®°å½•
func (ps *PositionScheduler) updateHedgeHistory(ctx context.Context,
	correlationMatrix *StrategyCorrelationMatrix,
	hedgeRatios []*DynamicHedgeRatio,
	hedgeResults []*HedgeResult) error {

	log.Printf("Updating hedge history")

	// åºåˆ—åŒ–ç›¸å…³æ€§çŸ©é˜µ
	matrixJSON := ps.serializeCorrelationMatrix(correlationMatrix)

	// è®¡ç®—æ€»ä½“ç»Ÿè®¡
	totalOperations := len(hedgeResults)
	successfulOperations := 0
	totalCost := 0.0
	totalRiskReduction := 0.0

	for _, result := range hedgeResults {
		if result.Success {
			successfulOperations++
		}
		totalCost += result.ActualCost
		totalRiskReduction += result.RiskReduction
	}

	successRate := float64(successfulOperations) / float64(totalOperations)
	avgCost := totalCost / float64(totalOperations)
	avgRiskReduction := totalRiskReduction / float64(totalOperations)

	// è®°å½•å†å²ï¼Œä½¿ç”¨æ­£ç¡®çš„è¡¨ç»“æ„å­—æ®µ
	query := `
		INSERT INTO hedge_history (
			hedge_id, strategy_ids, hedge_type, total_exposure, net_exposure,
			hedge_ratio, pnl, status, start_time, success_rate, metadata
		) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, NOW(), $9, $10)
	`

	// åˆ›å»ºå…ƒæ•°æ®JSON
	metadata := map[string]interface{}{
		"correlation_matrix": matrixJSON,
		"total_operations":   totalOperations,
		"avg_cost":           avgCost,
		"avg_risk_reduction": avgRiskReduction,
	}
	metadataJSON, err := json.Marshal(metadata)
	if err != nil {
		metadataJSON = []byte("{}")
	}

	hedgeID := fmt.Sprintf("hedge_%d", time.Now().UnixNano())

	// Extract strategy IDs from correlation matrix or hedge ratios
	var strategyIDs []string
	if correlationMatrix != nil && len(correlationMatrix.Strategies) > 0 {
		strategyIDs = correlationMatrix.Strategies
	}
	// If no strategy IDs found, use empty array
	if len(strategyIDs) == 0 {
		strategyIDs = []string{}
	}

	_, err = ps.db.ExecContext(ctx, query,
		hedgeID,               // hedge_id
		pq.Array(strategyIDs), // strategy_ids (PostgreSQL array)
		"correlation_hedge",   // hedge_type
		0.0,                   // total_exposure
		0.0,                   // net_exposure
		0.0,                   // hedge_ratio
		0.0,                   // pnl
		"completed",           // status
		successRate,           // success_rate
		string(metadataJSON),  // metadata
	)

	if err != nil {
		return fmt.Errorf("failed to update hedge history: %w", err)
	}

	log.Printf("Hedge history updated: %d operations, %.2f%% success rate",
		totalOperations, successRate*100)
	return nil
}

// serializeCorrelationMatrix åºåˆ—åŒ–ç›¸å…³æ€§çŸ©é˜µ
func (ps *PositionScheduler) serializeCorrelationMatrix(matrix *StrategyCorrelationMatrix) string {
	// ç®€åŒ–çš„JSONåºåˆ—åŒ–
	result := "{"
	for i, strategy1 := range matrix.Strategies {
		if i > 0 {
			result += ","
		}
		result += fmt.Sprintf(`"%s":{`, strategy1)
		for j, strategy2 := range matrix.Strategies {
			if j > 0 {
				result += ","
			}
			correlation := matrix.Matrix[strategy1][strategy2]
			result += fmt.Sprintf(`"%s":%.4f`, strategy2, correlation)
		}
		result += "}"
	}
	result += "}"
	return result
}
